# Arquitecturas cl√°sicas

## üïê Caso: Arquitectura de **WhatIsTheTime.com**

Aplicaci√≥n web sin estado que permite a los usuarios saber la hora actual. No requiere base de datos.

---

### üß™ **Etapa 1: Prueba de concepto (POC)**

- Se despliega en una sola **instancia EC2 t2.micro**.
- La instancia devuelve la hora del sistema.
- Se asigna una **Elastic IP** para acceso p√∫blico.

‚ùå **Problemas:**

- Monol√≠tica.
- Si cae la instancia, el servicio se interrumpe.
- Escalar verticalmente a una `m5.large` implica **tiempo de inactividad**.

---

### üìà **Etapa 2: Escalamiento horizontal**

- En vez de escalar verticalmente, se despliega una **segunda instancia EC2**.
- Se elimina la **Elastic IP**: ya no tiene sentido una IP fija si hay m√∫ltiples instancias.
- Se configura **Route 53** con un **registro A (api.whatisthetime.com)** con **TTL de 1 hora**.

‚ùå **Problemas:**

- Si una instancia se cae, y el TTL es alto, los usuarios seguir√°n consultando la IP incorrecta.

---

### ‚öñÔ∏è **Etapa 3: Alta disponibilidad con balanceador**

- Se introduce un **ELB (Elastic Load Balancer)**:

  - Expone una √∫nica IP p√∫blica.
  - Se encarga del **routing del tr√°fico a instancias sanas**.
  - Realiza **health checks** autom√°ticamente.

- Se reemplaza el **registro A** en Route 53 por un **registro Alias** apuntando al DNS del ELB.

‚úÖ **Beneficios:**

- Soporte para m√∫ltiples instancias sin manejar IPs manualmente.
- Soporte para escalamiento din√°mico.
- Conmutaci√≥n autom√°tica si una instancia falla.

---

### üìâ **Etapa 4: Auto Scaling & optimizaci√≥n de costes**

- Se configura un **ASG (Auto Scaling Group)**:

  - Capacidad m√≠nima: 2 instancias.
  - Capacidad deseada: ajustada seg√∫n tr√°fico.
  - Capacidad m√°xima: para picos de carga.

- Instancias en **m√∫ltiples AZ (Multi-AZ)** para alta disponibilidad.

> üí° Si una AZ falla (ej. terremoto), las instancias en otras zonas mantienen el servicio activo.

---

### üí∞ Optimizaci√≥n de costos

- Las instancias son **bajo demanda** inicialmente.
- Se puede usar **Capacity Reservation** o **Savings Plans / RI** para reservar capacidad con descuentos a largo plazo.

---

## üß© Conceptos usados

| Componente                     | Detalles                                                                        |
| ------------------------------ | ------------------------------------------------------------------------------- |
| **Elastic IP**                 | Fija para una instancia √∫nica, eliminada cuando se escala horizontalmente       |
| **Route 53**                   | Registro A (IP directa) ‚Üí Alias (apunta al ELB)                                 |
| **TTL**                        | Bajo TTL recomendado si se usan IPs variables (30s‚Äì60s)                         |
| **ELB**                        | Balanceo, health checks, integraci√≥n con ASG                                    |
| **ASG**                        | Escalado autom√°tico seg√∫n demanda, m√≠nimo 2 instancias para alta disponibilidad |
| **Instancias EC2**             | Sin estado, distribuidas en m√∫ltiples zonas                                     |
| **Grupos de seguridad**        | Definen el tr√°fico permitido hacia EC2 y ELB                                    |
| **Multi-AZ**                   | Mejora la resiliencia ante fallas en una AZ                                     |
| **Health Checks**              | ELB detecta instancias no saludables                                            |
| **Capacity Reservation / RIs** | Reserva capacidad con descuento para m√≠nimo 2 instancias                        |

---

## üèóÔ∏è Pilares del Well-Architected Framework aplicados

| Pilar                     | Aplicaci√≥n en la arquitectura                         |
| ------------------------- | ----------------------------------------------------- |
| üõ°Ô∏è Seguridad              | Grupos de seguridad, sin acceso directo a EC2         |
| üîÅ Fiabilidad             | Multi-AZ, ELB con health checks, ASG                  |
| üìà Rendimiento            | Escalado autom√°tico seg√∫n tr√°fico                     |
| üí∞ Optimizaci√≥n de costos | Escalado din√°mico, RIs o Savings Plans                |
| üß∞ Excelencia operativa   | Despliegue sencillo, sin estado, cambios sin downtime |

---

## üëó Caso: Arquitectura de **MyClothes.com**

Aplicaci√≥n web de e-commerce con estado (carrito de compras, datos del usuario) que:

- Tiene cientos de usuarios simult√°neamente.
- Requiere **escalabilidad horizontal**.
- Debe mantener la aplicaci√≥n **lo m√°s sin estado posible** para ser escalable y resiliente.
- Debe mantener **persistencia del carrito y datos del usuario**.

---

## üß† Desaf√≠o: ¬øC√≥mo mantener el estado del **carrito de compras**?

### 1Ô∏è‚É£ **Sticky sessions del ELB** (no recomendado para HA)

- Las **sticky sessions** permiten que un usuario se mantenga con la **misma instancia EC2** durante su sesi√≥n.
- Usan una cookie llamada `AWSELB`.

> ‚ùå Problema: si la instancia falla o hay un rebalanceo, **el estado se pierde**.

---

### 2Ô∏è‚É£ **Almacenar estado en cookies del cliente**

- El **carrito se serializa como JSON** en una cookie.
- Las instancias siguen siendo **sin estado**.
- El frontend maneja la carga del estado.

> ‚ö†Ô∏è Riesgos:

- Las cookies deben ser **< 4 KB**.
- Pueden ser manipuladas (riesgo de seguridad).
- Se debe implementar **validaci√≥n (firma, HMAC)**.
- Las peticiones HTTP ser√°n m√°s pesadas.

---

### 3Ô∏è‚É£ **Soluci√≥n ideal: almacenar sesiones en un backend compartido**

‚úÖ Mejor enfoque: usar un **backend compartido para sesiones** con un identificador √∫nico (`session_id`) en la cookie.

#### Alternativas

| Opci√≥n                         | Ventajas                                                                                | Consideraciones                                                     |
| ------------------------------ | --------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **Amazon ElastiCache (Redis)** | Millisegundos de latencia, soporte a expiraci√≥n de sesiones, estructuras como hash/zset | Se debe usar **Multi-AZ** y grupos de seguridad                     |
| **Amazon DynamoDB**            | Sin servidor, escalado autom√°tico, TTL para expiraci√≥n de sesiones                      | Latencia mayor, pero buena para aplicaciones distribuidas o m√≥viles |

üí° Patr√≥n cl√°sico:

1. Cliente env√≠a `session_id` (cookie segura).
2. EC2 o Lambda lee sesi√≥n desde **Redis o DynamoDB**.
3. Devuelve respuesta con estado persistido.

---

## üßæ Almacenamiento de datos del usuario

- Se usa **Amazon RDS** (ej: MySQL/PostgreSQL) para datos como nombre, direcci√≥n, historial de pedidos.
- Se puede aplicar **modelo maestro-esclavo**:

### üîÅ Replicaci√≥n

- **Instancia principal** ‚Üí solo escritura.
- **R√©plica(s) de lectura** ‚Üí para balancear cargas de consultas.

üí° Alternativa avanzada:

- **Elasticache como capa de cach√© delante de RDS**:

  - Si hay **hit**: responde desde cach√©.
  - Si hay **miss**: consulta RDS y cachea el resultado.

---

## üåç Alta disponibilidad

- **Instancias EC2 y bases de datos distribuidas en varias AZ** (Multi-AZ).
- Si una AZ falla, los recursos siguen funcionando desde otra.
- **ElastiCache tambi√©n debe configurarse en modo Multi-AZ (con Redis cluster y r√©plica)**.

---

## üîí Seguridad

| Recurso            | Medida                                                                    |
| ------------------ | ------------------------------------------------------------------------- |
| EC2 ‚Üî ElastiCache  | Grupos de seguridad deben permitir solo el tr√°fico necesario              |
| EC2 ‚Üî RDS          | Acceso restringido por grupo de seguridad                                 |
| Base de datos      | Usuarios con m√≠nimos privilegios, sin acceso p√∫blico                      |
| Cookies de sesi√≥n  | Deben estar firmadas o encriptadas si contienen datos sensibles           |
| Redis (AUTH) o SSL | Activar si aplica, especialmente con ElastiCache p√∫blico (no recomendado) |

---

## üìã Resumen general de decisiones

| Componente                     | Funci√≥n                                        |
| ------------------------------ | ---------------------------------------------- |
| **Sticky session (ELB)**       | ‚ùå Solo √∫til si hay una √∫nica instancia        |
| **Cookies de usuario**         | ‚úÖ Posible, pero limitada y riesgosa           |
| **ElastiCache (Redis)**        | ‚úÖ Ideal para sesiones r√°pidas, TTL, multi-AZ  |
| **DynamoDB**                   | ‚úÖ Alternativa serverless, buena escalabilidad |
| **RDS maestro + r√©plicas**     | ‚úÖ Almac√©n duradero para datos de usuario      |
| **Multi-AZ EC2 / Redis / RDS** | ‚úÖ Alta disponibilidad y tolerancia a fallos   |
| **Grupos de seguridad**        | ‚úÖ Control granular del tr√°fico                |

---

## üß† Pilares del AWS Well-Architected Framework

| Pilar                     | Aplicaci√≥n                                                      |
| ------------------------- | --------------------------------------------------------------- |
| üí∞ Cost Optimization      | Cacheo de lecturas, instancias por demanda con ASG              |
| ‚öôÔ∏è Operational Excellence | Sin estado, sesiones desacopladas, escalado autom√°tico          |
| üîÅ Reliability            | Multi-AZ en todos los componentes cr√≠ticos                      |
| üîê Security               | Cookies seguras, tr√°fico interno controlado, usuarios limitados |
| üìà Performance Efficiency | Redis para sesiones, r√©plicas para lecturas, TTLs               |

## üìù Caso: Arquitectura de **myWordpress.com**

Sitio web basado en WordPress que:

- Muestra contenido din√°mico (posts, usuarios, sesiones).
- Sube im√°genes desde el frontend.
- Usa una base de datos MySQL.
- Requiere **alta disponibilidad**, **persistencia de datos** y **escalabilidad horizontal**.

---

## üß± Arquitectura inicial

| Componente                    | Uso                                                            |
| ----------------------------- | -------------------------------------------------------------- |
| **Amazon Route 53**           | DNS para `www.mywordpress.com`                                 |
| **ELB (ALB/NLB)**             | Balanceador para distribuir tr√°fico entre instancias           |
| **Auto Scaling Group (ASG)**  | Escala horizontalmente las EC2                                 |
| **Amazon EC2 (m5.large)**     | Servidor de WordPress                                          |
| **Amazon RDS MySQL Multi-AZ** | Base de datos relacional para posts, usuarios, configuraciones |
| **EBS (Elastic Block Store)** | Disco persistente para cada instancia                          |

---

### ‚ùå Problema con EBS

- EBS est√° **acoplado a una sola instancia EC2**.
- Si el usuario sube una imagen a `instancia-1`, y en su siguiente solicitud va a `instancia-2`, esa imagen **no estar√° disponible**.

---

## ‚úÖ Soluci√≥n: almacenamiento compartido

| Recurso                                  | Soluci√≥n                                                          |
| ---------------------------------------- | ----------------------------------------------------------------- |
| üì∑ Subida de im√°genes                    | Usar **EFS** (Elastic File System) para almacenamiento compartido |
| üíæ Datos estructurados (posts, usuarios) | Usar **Aurora MySQL** (escalable y resiliente)                    |

---

### üóÉÔ∏è Amazon EFS

| Caracter√≠stica  | Detalle                                                        |
| --------------- | -------------------------------------------------------------- |
| Tipo            | File System compartido y el√°stico                              |
| Acceso          | Todas las instancias EC2 pueden montarlo por NFS               |
| Multi-AZ        | ‚úÖ Alta disponibilidad por dise√±o                              |
| Montaje         | A trav√©s de **ENI (Elastic Network Interface)** en cada AZ     |
| Escenario ideal | Compartir recursos como im√°genes, archivos de usuario, plugins |

> ‚ö†Ô∏è EFS no es ideal para objetos grandes y fr√≠os ‚Üí ah√≠ entra S3.

---

## üß† ¬øPor qu√© no usar S3 directamente para WordPress?

| S3 es excelente para...                                            | Pero...                                                              |
| ------------------------------------------------------------------ | -------------------------------------------------------------------- |
| Sitios est√°ticos, archivos JS/CSS, backups, multimedia distribuida | WordPress espera un **sistema de archivos** tradicional para uploads |
| Plugins como WP Offload Media permiten mover los uploads a S3      | Requiere ajustes extra, **no plug-and-play**                         |

---

## üíæ Aurora MySQL para WordPress

| Funcionalidad       | Detalle                                              |
| ------------------- | ---------------------------------------------------- |
| Motor               | Aurora compatible con MySQL                          |
| Modo Multi-AZ       | Alta disponibilidad autom√°tica                       |
| R√©plicas de lectura | Para escalar consultas pesadas sin afectar escritura |
| Escenario ideal     | Wordpress con mucho tr√°fico, lecturas constantes     |

---

## üîê Seguridad

| Recurso        | Medidas recomendadas                                               |
| -------------- | ------------------------------------------------------------------ |
| RDS/Aurora     | Solo accesible desde SG de EC2                                     |
| EFS            | Solo montable desde instancias en la misma VPC y con SG autorizado |
| EC2            | SG con acceso solo desde el ELB                                    |
| EFS Encryption | Activar cifrado en reposo y en tr√°nsito                            |

---

## üìã Resumen t√©cnico

| Componente   | Funci√≥n                      | Tipo                         |
| ------------ | ---------------------------- | ---------------------------- |
| Route 53     | DNS de `www.mywordpress.com` | Alta disponibilidad          |
| ELB          | Balancea tr√°fico entre EC2   | Escalabilidad                |
| ASG          | Escala horizontal EC2        | Performance y disponibilidad |
| EC2 (m5)     | Servidor WordPress           | Stateless (con EFS)          |
| EBS          | Temporal / Sistema base      | Por instancia                |
| EFS          | Im√°genes / Uploads           | Compartido, Multi-AZ         |
| Aurora MySQL | Base de datos de WordPress   | Multi-AZ, escalable          |
| ENI          | Permite conexi√≥n a EFS       | Por zona                     |

---

## üß† Diferencia entre EBS, EFS y S3

| Recurso | Tipo     | ¬øCompartido? | Persistencia | Acceso                                    |
| ------- | -------- | ------------ | ------------ | ----------------------------------------- |
| **EBS** | Bloques  | ‚ùå No        | ‚úÖ S√≠        | Solo 1 instancia                          |
| **EFS** | Archivos | ‚úÖ S√≠        | ‚úÖ S√≠        | Varias instancias v√≠a NFS                 |
| **S3**  | Objetos  | ‚úÖ S√≠        | ‚úÖ S√≠        | Acceso HTTP (no como sistema de archivos) |

---

## ‚úÖ Pilares del Well-Architected Framework aplicados

| Pilar                     | Aplicaci√≥n                                             |
| ------------------------- | ------------------------------------------------------ |
| üîÅ Fiabilidad             | Aurora Multi-AZ + R√©plicas, EC2 Multi-AZ, EFS Multi-AZ |
| üí∞ Cost Optimization      | ASG para escalar seg√∫n demanda, lectura en Aurora      |
| üîê Seguridad              | Grupos de seguridad estrictos, cifrado EFS/RDS         |
| üìà Performance Efficiency | R√©plicas de lectura, EFS para m√∫ltiples EC2            |
| ‚öôÔ∏è Operational Excellence | Separaci√≥n de capas, despliegues sin acoplamiento      |

## üß± Arquitectura web cl√°sica de 3 niveles en AWS

Esta arquitectura suele componerse de:

| Capa                   | Componentes t√≠picos                                  |
| ---------------------- | ---------------------------------------------------- |
| üîì **Subred p√∫blica**  | ELB (ALB o NLB), NAT Gateway                         |
| üñ•Ô∏è **Subred privada**  | EC2 (web/app servers), Auto Scaling Group            |
| üóÉÔ∏è **Subred de datos** | RDS, ElastiCache, a veces S3 para recursos est√°ticos |

---

## ‚ö†Ô∏è Problemas comunes para desarrolladores

Aunque esta arquitectura es s√≥lida y escalable, puede generar **fricci√≥n** para equipos de desarrollo:

| √Årea                                   | Dificultad                                                                |
| -------------------------------------- | ------------------------------------------------------------------------- |
| üîß **Gesti√≥n de infraestructura**      | Hay que definir y mantener VPCs, subredes, grupos de seguridad, ELB, etc. |
| üöÄ **Despliegue del c√≥digo**           | Hay que coordinar pipelines, instalaci√≥n de dependencias, configuraciones |
| ‚öôÔ∏è **Configuraci√≥n de bases de datos** | Usuarios, backups, subredes privadas, endpoints, etc.                     |
| üìà **Escalado horizontal/vertical**    | Requiere configurar ASG, pol√≠ticas de escalado, m√©tricas                  |
| üí∞ **Costos y optimizaci√≥n**           | Ajustar tipos de instancia, escalado y tiempos de vida                    |

---

## üå± ¬øQu√© es Elastic Beanstalk?

**Elastic Beanstalk** es un servicio **gestionado** que permite a los desarrolladores **desplegar y escalar r√°pidamente aplicaciones web y servicios** sin gestionar la infraestructura subyacente.

### üí° Principio clave

> _"T√∫ subes el c√≥digo, Beanstalk hace el resto."_

---

## ‚úÖ Beneficios clave de Beanstalk

| Ventaja           | Explicaci√≥n                                                                      |
| ----------------- | -------------------------------------------------------------------------------- |
| ‚öôÔ∏è Automatizaci√≥n | Maneja aprovisionamiento, escalado, monitoreo y despliegue                       |
| üß† Abstracci√≥n    | Oculta detalles complejos como VPC, ELB, ASG, etc.                               |
| ü™ü Visibilidad    | A√∫n puedes ver y modificar los recursos creados                                  |
| üéØ Integraci√≥n    | Compatible con CloudFormation, CloudWatch, IAM, RDS, etc.                        |
| üí∏ Costo          | El servicio **no tiene costo adicional**, solo pagas por los recursos utilizados |

---

## üß© Componentes de Elastic Beanstalk

| Componente                   | Descripci√≥n                                                                 |
| ---------------------------- | --------------------------------------------------------------------------- |
| **Aplicaci√≥n**               | Contenedor l√≥gico del proyecto (puede tener m√∫ltiples versiones y entornos) |
| **Versi√≥n de la aplicaci√≥n** | C√≥digo + configuraci√≥n espec√≠fica que puede ser desplegada                  |
| **Entorno**                  | Colecci√≥n de recursos donde corre una versi√≥n espec√≠fica de la aplicaci√≥n   |

---

## üéõÔ∏è Tipos de entornos en Beanstalk

### üåê Entorno web (web server environment)

- Contiene:

  - ELB
  - ASG
  - Instancias EC2

- Maneja peticiones HTTP/HTTPS
- Ideal para sitios web, APIs, frontends

### ‚öôÔ∏è Entorno de trabajo (worker environment)

- Contiene:

  - SQS (cola de tareas)
  - EC2 (workers)

- Las peticiones se encolan y los workers las procesan de forma as√≠ncrona
- Ideal para procesamiento en segundo plano (env√≠o de emails, procesamiento de im√°genes, tareas pesadas)

üí¨ **Los entornos pueden comunicarse entre s√≠**, por ejemplo:

- El **frontend web** encola tareas en SQS
- El **entorno worker** las consume y ejecuta

---

## üß† Plataformas soportadas por Beanstalk

| Lenguaje / Plataforma            | ¬øSoportado? |
| -------------------------------- | ----------- |
| Go                               | ‚úÖ          |
| Java SE, Tomcat                  | ‚úÖ          |
| .NET (Core y Framework)          | ‚úÖ          |
| PHP                              | ‚úÖ          |
| Node.js                          | ‚úÖ          |
| Python                           | ‚úÖ          |
| Ruby                             | ‚úÖ          |
| Docker                           | ‚úÖ          |
| Custom platform (Packer Builder) | ‚úÖ          |

> Puedes traer tu propio contenedor o construir una plataforma personalizada con Packer si necesitas m√°s control.

---

## üß≠ Flujo t√≠pico de uso

1. Desarrollador hace push del c√≥digo (`zip`, `git`, `eb deploy`, etc.)
2. Elastic Beanstalk crea o actualiza el entorno con:

   - ELB
   - EC2 + ASG
   - RDS opcional

3. Se monitorea desde CloudWatch
4. Si falla el entorno, puedes hacer rollback con otra versi√≥n

---

## üìã Resumen final

| Tema                 | Detalle                                                             |
| -------------------- | ------------------------------------------------------------------- |
| Arquitectura cl√°sica | 3 capas: p√∫blica, privada, datos                                    |
| Problema             | Mucho manejo de infraestructura                                     |
| Soluci√≥n             | Elastic Beanstalk abstrae la complejidad                            |
| Control              | Puedes personalizar recursos si lo necesitas                        |
| Costos               | Solo por lo que usas (Beanstalk en s√≠ es gratuito)                  |
| Ideal para           | Desarrolladores que quieren enfocarse en c√≥digo, no infraestructura |

## üßä Movimiento entre clases de almacenamiento en S3

Amazon S3 ofrece **varias clases de almacenamiento**, dise√±adas para diferentes patrones de acceso y requisitos de costo. Puedes mover objetos entre ellas **autom√°ticamente** mediante reglas de **ciclo de vida (Lifecycle rules)**.

---

### üì¶ Principales clases de almacenamiento

| Clase                       | Descripci√≥n                                                     | Uso ideal                         |
| --------------------------- | --------------------------------------------------------------- | --------------------------------- |
| **S3 Standard**             | Alta disponibilidad, baja latencia                              | Archivos accedidos frecuentemente |
| **S3 Standard-IA**          | Infrequent Access: bajo costo, pero con tarifa por recuperaci√≥n | Archivos accedidos ocasionalmente |
| **S3 One Zone-IA**          | Similar a Standard-IA, pero solo en 1 AZ                        | Backups no cr√≠ticos               |
| **S3 Glacier**              | Archivo con acceso en minutos u horas                           | Archivado de datos a largo plazo  |
| **S3 Glacier Deep Archive** | Acceso en 12-48h, m√°s econ√≥mico                                 | Archivado casi hist√≥rico          |
| **S3 Intelligent-Tiering**  | Mueve objetos autom√°ticamente seg√∫n patrones de acceso          | Datos con accesos impredecibles   |

---

## üîÅ Transiciones de clase (Lifecycle Transitions)

Puedes configurar reglas que **transicionen objetos de una clase a otra** despu√©s de un n√∫mero de d√≠as.

### üß† Ejemplo t√≠pico:

1. **D√≠a 0:** Objeto guardado en **S3 Standard**
2. **D√≠a 60:** Mover a **S3 Standard-IA**
3. **D√≠a 180:** Mover a **S3 Glacier**
4. **D√≠a 365:** Eliminar el objeto (opcional)

---

## üîÑ Reglas del ciclo de vida (Lifecycle Rules)

### üìå ¬øQu√© pueden hacer?

- **Transicionar objetos entre clases** seg√∫n edad.
- **Eliminar objetos autom√°ticamente** (expiraci√≥n).
- **Aplicarse a todo el bucket o a subconjuntos** por:

  - **Prefijo** (por ejemplo: `logs/`)
  - **Etiquetas (tags)** (por ejemplo: `{"archivado": "s√≠"}`)

### üìò Sintaxis com√∫n en consola:

```plaintext
Transici√≥n:
- Si objeto tiene m√°s de 60 d√≠as ‚Üí IA
- Si objeto tiene m√°s de 180 d√≠as ‚Üí Glacier

Expiraci√≥n:
- Si objeto tiene m√°s de 365 d√≠as ‚Üí eliminar
```

---

## üß™ Casos de uso comunes

| Caso                           | Clase de destino     |
| ------------------------------ | -------------------- |
| Logs que se consultan poco     | IA o Glacier         |
| Archivos de cumplimiento legal | Glacier Deep Archive |
| Cach√©s est√°ticas               | S3 Standard          |
| Backups diarios                | IA o One Zone-IA     |

---

## üí° Recomendaciones

- Usa **tags** para tener reglas espec√≠ficas sin afectar todo el bucket.
- Glacier y Deep Archive no son instant√°neos: ten presente los **tiempos de recuperaci√≥n**.
- S3 Intelligent-Tiering puede ayudarte si **no sabes con certeza** c√≥mo se acceder√°n los datos.

---

## üìã Resumen

| Elemento                 | Detalle                                                           |
| ------------------------ | ----------------------------------------------------------------- |
| Clases de almacenamiento | 6 principales, cada una con casos de uso                          |
| Movimiento entre clases  | Se hace con **acciones de transici√≥n** en reglas de ciclo de vida |
| Eliminaci√≥n autom√°tica   | Se hace con **acciones de expiraci√≥n**                            |
| Aplicaci√≥n de reglas     | Por **prefijo**, **tag** o global                                 |
| Costo eficiente          | Reduce costos al mover archivos inactivos a clases m√°s baratas    |
| Automatizable            | ‚úÖ 100% con lifecycle rules y sin necesidad de scripts externos   |

## üìä Amazon S3 Storage Class Analysis (Analytics)

### üéØ ¬øPara qu√© sirve?

**S3 Analytics** te ayuda a analizar los patrones de acceso a los objetos almacenados en un bucket para decidir **cu√°ndo moverlos autom√°ticamente a una clase de almacenamiento m√°s econ√≥mica**, como **S3 Standard-IA**.

> Es √∫til especialmente cuando **no est√°s seguro de la frecuencia de acceso a tus datos**.

---

## ‚úÖ Casos de uso ideal

- Buckets con objetos en **S3 Standard** que podr√≠an beneficiarse del cambio a **S3 Standard-IA**.
- An√°lisis previo antes de configurar reglas de ciclo de vida.
- Proyectos con gran volumen de datos y comportamiento variable.

---

## üß† C√≥mo funciona

1. **Activas Analytics** en un bucket o prefijo.
2. AWS comienza a recopilar datos de acceso.
3. Despu√©s de **24 a 48 horas**, empiezas a recibir reportes.
4. Se actualiza **diariamente** y muestra:

   - Bytes almacenados
   - N√∫mero de objetos
   - Frecuencia de acceso
   - Porcentaje de acceso reciente vs hist√≥rico

5. T√∫ decides si mover esos objetos a IA o no.

---

## üìÅ Aplicabilidad

- Puedes aplicar el an√°lisis a **todo el bucket**, a **un prefijo espec√≠fico** o a **objetos con ciertas etiquetas (tags)**.
- Esto te da granularidad: puedes analizar solo los objetos que te interesan.

---

## üìâ Ejemplo de an√°lisis

Supongamos que tienes un bucket con 100 GB de datos. S3 Analytics puede mostrarte:

| Prefijo      | Tama√±o | % Accedido √∫ltimos 30 d√≠as | ¬øConviene IA? |
| ------------ | ------ | -------------------------- | ------------- |
| `/logs/`     | 30 GB  | 2%                         | ‚úÖ            |
| `/images/`   | 50 GB  | 85%                        | ‚ùå            |
| `/archivos/` | 20 GB  | 5%                         | ‚úÖ            |

---

## üß© Integraci√≥n con reglas de ciclo de vida

Una vez identificados los datos que no se acceden frecuentemente, puedes:

- Crear reglas de **transici√≥n** a **IA o Glacier**
- Crear reglas de **expiraci√≥n**
- Aplicar reglas a los prefijos analizados

> üìå **S3 Analytics no realiza la transici√≥n autom√°ticamente**, pero **es un primer paso crucial**.

---

## üõë Limitaciones

| Limitaci√≥n        | Detalle                                                                                        |
| ----------------- | ---------------------------------------------------------------------------------------------- |
| Tiempo inicial    | Tarda **24-48h** en generar los primeros informes                                              |
| Clases soportadas | Solo compara entre **S3 Standard** y **S3 Standard-IA**                                        |
| Costo             | **Gratuito** dentro del servicio de S3, pero hay cargos normales por almacenamiento y requests |
| No analiza        | Glacier, Deep Archive, Intelligent-Tiering, etc.                                               |

---

## üìã Resumen

| Tema                   | Detalle                                          |
| ---------------------- | ------------------------------------------------ |
| Qu√© es                 | Herramienta para analizar el acceso a objetos    |
| Objetivo               | Ayudar a decidir si conviene mover a Standard-IA |
| Frecuencia de an√°lisis | Diario                                           |
| Tiempo inicial         | Primer informe: 24-48 horas                      |
| Aplicable por          | Bucket, prefijo, o etiqueta                      |
| Ideal para             | Crear reglas de ciclo de vida informadas         |
| Automatizaci√≥n         | No realiza cambios, solo analiza                 |

## üí∞ S3 ‚Äú**Requester Pays**‚Äù buckets

| Concepto                     | Detalle                                                                                                                                                                                                                         |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **¬øQu√© resuelve?**           | El **propietario** de un bucket paga siempre el **almacenamiento**. Con _Requester Pays_ el **coste de las peticiones y de la transferencia de datos** (GET, LIST, PUT, egress) lo asume **quien descarga o sube los objetos**. |
| **Cu√°ndo usarlo**            | - Compartir grandes datasets (logs, im√°genes satelitales, genomics‚Ä¶) sin cargar al due√±o.<br>- Repositorios p√∫blicos de investigaci√≥n donde cada equipo cubre su propio ancho de banda.                                         |
| **Requisitos**               | üîê El solicitante **debe autenticarse** con una cuenta AWS (no funciona para acceso an√≥nimo).<br>üîë La **pol√≠tica**/ACL debe autorizar la acci√≥n solicitada.<br>üåê Aplica tanto a Internet como a VPC Endpoints.                |
| **Qui√©n paga qu√©**           | Propietario ‚áí _GB-mes de almacenamiento_.<br>Solicitante ‚áí _Requests_, **Data Transfer OUT**, **Data Transfer IN** (si aplica).                                                                                                 |
| **Clases de almacenamiento** | Funciona con todas; los recargos (ej. Glacier retrieval) tambi√©n los paga el solicitante.                                                                                                                                       |

---

### üîß C√≥mo activarlo

```bash
aws s3api put-bucket-request-payment \
  --bucket my-dataset-bucket \
  --request-payment-configuration Payer=Requester
```

_Para comprobar:_

```bash
aws s3api get-bucket-request-payment --bucket my-dataset-bucket
```

---

### üõÇ Pol√≠tica m√≠nima de acceso (ejemplo)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "ReadOnlyRequesterPays",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject"],
      "Resource": "arn:aws:s3:::my-dataset-bucket/*"
    }
  ]
}
```

> Aunque la pol√≠tica permita `*`, cada requester **debe** usar `--request-payer requester` (CLI/SDK) para que la operaci√≥n prospere y se le facture.

---

### üß™ Uso desde CLI por parte del solicitante

```bash
aws s3 cp s3://my-dataset-bucket/bigfile.csv ./ \
  --request-payer requester
```

Sin el flag, la llamada devuelve **403 Access Denied**.

---

### ‚ö†Ô∏è Consideraciones

- **Costes inesperados**: el propietario sigue pagando el almacenamiento diario.
- **Logging**: habilita Server Access Logs o CloudTrail para auditor√≠a.
- **Cross-Account**: combina _Requester Pays_ con **Bucket Policy** o **Access Points** para precisar permisos.
- **No caching de CloudFront gratuito**: si pones el bucket detr√°s de CloudFront, el due√±o del CloudFront paga el egress desde la edge, no el requester.

---

### üìù Resumen r√°pido

1. _Requester Pays_ = el **requester** paga **requests + transferencia**.
2. Propietario **siempre** paga **almacenamiento**.
3. Requiere **autenticaci√≥n AWS** y `--request-payer requester`.
4. Perfecto para compartir datasets voluminosos sin facturas sorpresa.

## üì£ Notificaciones de eventos de Amazon S3

### üéØ ¬øQu√© son?

Permiten a S3 **notificar autom√°ticamente** cuando ocurren ciertos eventos sobre los objetos en un bucket, como:

- Subida (`s3:ObjectCreated:*`)
- Eliminaci√≥n (`s3:ObjectRemoved:*`)
- Restauraci√≥n desde Glacier
- Fallos de replicaci√≥n
- Cambios en el ciclo de vida

---

## üìç Destinos compatibles

| Destino         | ¬øPara qu√© sirve?                                                       | Caracter√≠sticas                                                   |
| --------------- | ---------------------------------------------------------------------- | ----------------------------------------------------------------- |
| **SNS**         | Publicar notificaciones a m√∫ltiples suscriptores (email, SMS, HTTP...) | Env√≠o masivo y fan-out                                            |
| **SQS**         | Encolar eventos para procesamiento posterior por consumidores          | Asegura el orden, desacopla procesamiento                         |
| **Lambda**      | Ejecutar l√≥gica directamente sobre un evento                           | Serverless, reactivo, c√≥digo en tiempo real                       |
| **EventBridge** | Motor de eventos con reglas avanzadas, m√∫ltiples destinos y fiabilidad | Filtros JSON, redirecci√≥n de eventos, almacenamiento y repetici√≥n |

---

## üîÅ Flujo t√≠pico

1. Se sube un archivo al bucket (ej. `PUT`).
2. S3 detecta el evento `ObjectCreated:Put`.
3. Env√≠a notificaci√≥n al destino configurado (ej. SQS, Lambda, etc).
4. El destino reacciona (procesa, transforma, almacena‚Ä¶).

---

## üîß Configuraci√≥n b√°sica (SQS, SNS, Lambda)

Se puede hacer por:

- **Consola**
- **AWS CLI**
- **S3 API** (v√≠a `NotificationConfiguration`)

```json
{
  "LambdaFunctionConfigurations": [
    {
      "LambdaFunctionArn": "arn:aws:lambda:region:account:function:processImage",
      "Events": ["s3:ObjectCreated:*"],
      "Filter": {
        "Key": {
          "FilterRules": [
            {
              "Name": "suffix",
              "Value": ".jpg"
            }
          ]
        }
      }
    }
  ]
}
```

> Tambi√©n puedes usar prefijos (`prefix`) para limitar eventos a carpetas espec√≠ficas.

---

## üî• Ventajas de usar EventBridge con S3

| Ventaja                           | Detalle                                                                                                |
| --------------------------------- | ------------------------------------------------------------------------------------------------------ |
| üéØ **Filtros potentes en JSON**   | Puedes hacer filtros por prefijo, sufijo, bucket name, regi√≥n, o campos personalizados                 |
| üö¶ **Ruteo avanzado**             | Puedes dirigir eventos a m√∫ltiples destinos: Lambda, Step Functions, Kinesis, SNS, SQS, otros EventBus |
| üïí **Reintento y entrega fiable** | Reintentos autom√°ticos y Dead Letter Queues                                                            |
| üîÑ **Repetici√≥n de eventos**      | Puedes volver a emitir eventos pasados almacenados en EventBridge                                      |
| üß© **Integraci√≥n con SaaS**       | Puedes capturar eventos de servicios SaaS como Datadog, Auth0, MongoDB Atlas                           |
| üóÇÔ∏è **Archivado de eventos**       | Puedes conservar eventos hist√≥ricos por tiempo definido                                                |

---

## üß† Cu√°ndo usar qu√©

| Escenario                                        | Mejor opci√≥n |
| ------------------------------------------------ | ------------ |
| Reacci√≥n simple al subir archivo                 | Lambda       |
| Procesamiento en cola por lotes                  | SQS          |
| Publicaci√≥n a m√∫ltiples sistemas                 | SNS          |
| Necesitas filtros complejos o m√∫ltiples destinos | EventBridge  |

---

## üß™ Ejemplo de caso real

> Se sube un archivo `.csv` al bucket `data-ingest`, y se debe:

- Validar el archivo con Lambda
- Enviar notificaci√≥n al equipo v√≠a SNS
- Registrar el evento en una base de eventos

üìå Soluci√≥n:

- S3 env√≠a eventos a **EventBridge**
- EventBridge enruta a:

  - Lambda para validaci√≥n
  - SNS para alerta
  - Firehose o DynamoDB v√≠a Lambda para almacenar eventos

---

## üßæ Resumen

| Tema                 | Detalle                                                                      |
| -------------------- | ---------------------------------------------------------------------------- |
| ¬øQu√© son?            | Eventos autom√°ticos que lanza S3 ante acciones sobre objetos                 |
| Destinos directos    | SNS, SQS, Lambda                                                             |
| Destino avanzado     | EventBridge                                                                  |
| EventBridge ventajas | Filtros JSON, m√∫ltiples destinos, repetici√≥n, archivado, DLQ                 |
| Configuraci√≥n        | Por consola, CLI o `NotificationConfiguration`                               |
| Casos comunes        | Subida de im√°genes, workflows de ingesta, validaciones, eventos distribuidos |

## üöÄ Rendimiento en Amazon S3

Amazon S3 est√° dise√±ado para **escalar autom√°ticamente** para soportar cargas de trabajo con alta demanda de lectura y escritura, sin necesidad de que t√∫ administres el escalado.

---

### üìà L√≠mites de rendimiento por **prefijo**

| Operaci√≥n                      | L√≠mite por segundo **por prefijo** |
| ------------------------------ | ---------------------------------- |
| **PUT / COPY / POST / DELETE** | 3,500 requests/segundo             |
| **GET / HEAD**                 | 5,500 requests/segundo             |

üìå **No hay l√≠mite en la cantidad de prefijos** que puede tener un bucket, por lo tanto puedes escalar horizontalmente tu carga de trabajo creando m√°s prefijos (por ejemplo: `img/2025/07/`, `img/2025/08/`‚Ä¶).

#### üí° Recomendaci√≥n

> Distribuye objetos entre **m√∫ltiples prefijos** si esperas un volumen muy alto de solicitudes concurrentes.

---

### üß© Carga de varias partes (Multipart Upload)

| Caracter√≠stica  | Detalle                                                                                                                                                  |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| ¬øQu√© hace?      | Divide un archivo grande en partes independientes que se suben en paralelo                                                                               |
| ¬øCu√°ndo usarlo? | Recomendado: archivos > 100 MB<br>Obligatorio: archivos > 5 GB                                                                                           |
| ¬øVentajas?      | - Mejora el rendimiento<br>- Recuperaci√≥n ante errores<br>- Posibilidad de reintento de partes fallidas<br>- Compatible con aceleraci√≥n de transferencia |
| ¬øC√≥mo funciona? | 1. Inicia carga<br>2. Sube partes<br>3. Finaliza la carga                                                                                                |

> Se puede hacer desde AWS CLI, SDK o S3 Console (archivos grandes).

---

### üåç Aceleraci√≥n de transferencia en S3 (Transfer Acceleration)

| Caracter√≠stica | Detalle                                                                                                                                              |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| ¬øQu√© hace?     | Usa **Amazon CloudFront** (edge locations) para acelerar la subida y descarga de archivos a S3                                                       |
| ¬øBeneficios?   | - Reducci√≥n de latencia en cargas y descargas<br>- Ideal para cargas de archivos desde ubicaciones globales<br>- Compatible con **multipart upload** |
| ¬øC√≥mo usarla?  | Habilita la opci√≥n en tu bucket y usa la URL `bucketname.s3-accelerate.amazonaws.com`                                                                |

> Ejemplo: para apps m√≥viles o clientes globales que cargan im√°genes o documentos a un bucket centralizado.

---

### üì¶ Recuperaci√≥n de rango de bytes (Range GET)

| Caracter√≠stica   | Detalle                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| ¬øQu√© hace?       | Permite recuperar **solo una parte de un objeto** especificando el **rango de bytes**                                                         |
| ¬øPara qu√© sirve? | - **Descarga paralela** de un archivo grande<br>- **Reanudar descargas** incompletas<br>- **Procesamiento parcial** sin bajar todo el archivo |
| ¬øEjemplo?        | Descargar bytes 0‚Äì999 de un archivo:                                                                                                          |

```http
Range: bytes=0-999
```

üìå Ideal para descargas por partes en clientes como video streaming, grandes backups o descargas multi-threaded.

---

## üß† Casos de uso combinados

| Requisito                              | T√©cnica recomendada                  |
| -------------------------------------- | ------------------------------------ |
| Subida de archivos de 10 GB            | Multipart upload                     |
| Subida r√°pida desde Asia               | Transfer Acceleration                |
| Muchas descargas simult√°neas           | Distribuir prefijos y usar Range GET |
| Acceso concurrente de objetos          | M√°s prefijos = m√°s rendimiento       |
| Reanudar descargas sin repetir todo    | Range GET                            |
| Mejorar resiliencia en uploads grandes | Multipart upload con reintentos      |

---

## üìã Resumen final

| Tema                   | Detalle                                         |
| ---------------------- | ----------------------------------------------- |
| L√≠mites de rendimiento | 3.5K escritura / 5.5K lectura por prefijo       |
| Escalado               | Usa m√∫ltiples prefijos para mayor rendimiento   |
| Multipart Upload       | Paraleliza subidas, mejora tolerancia a fallos  |
| Transfer Acceleration  | Usa edge locations para mejorar latencia        |
| Range GET              | Descarga parcial o paralela de archivos grandes |

## üß† ¬øQu√© es S3 Select?

**S3 Select** te permite ejecutar **consultas SQL directamente sobre objetos almacenados en S3**, sin necesidad de descargar el objeto completo a tu aplicaci√≥n o servidor.

---

### üéØ ¬øQu√© resuelve?

‚úÖ **Filtrado de datos del lado del servidor**, antes de enviarlos por red.
‚úÖ **Reducci√≥n del volumen de datos transferidos**, y del uso de **CPU en el cliente**.
‚úÖ Ideal para leer **solo columnas o filas espec√≠ficas** de archivos grandes como CSV, JSON o Apache Parquet.

---

### üìä ¬øC√≥mo funciona?

1. El objeto (CSV, JSON, Parquet) est√° almacenado en S3.
2. Ejecutas una consulta SQL como:

   ```sql
   SELECT s.name, s.age FROM S3Object s WHERE s.age > 25
   ```

3. S3 procesa el archivo **dentro del servicio**.
4. Devuelve **solo las filas y columnas que cumplen la condici√≥n**.

> üî∏ Esto permite ahorro de ancho de banda, menos espera y menor uso de recursos cliente.

---

### üìÅ Formatos soportados por S3 Select

| Formato        | Soportado |
| -------------- | --------- |
| CSV            | ‚úÖ        |
| JSON           | ‚úÖ        |
| Apache Parquet | ‚úÖ        |

üìå Comprimidos en GZIP o BZIP2: s√≠, siempre y cuando no est√©n divididos en m√∫ltiples bloques internos.

---

## üßä Glacier Select

Funciona de forma muy similar a S3 Select, pero sobre **archivos archivados en S3 Glacier** o **Glacier Deep Archive**.

- Permite ejecutar consultas SQL para recuperar **solo una parte del archivo archivado**.
- Reduce el **costo y tiempo de recuperaci√≥n**, ya que no necesitas restaurar todo el archivo.

üîÅ Los pasos son similares: lanzas una consulta SQL, y Glacier devuelve solo el subconjunto filtrado.

> üí° Es especialmente √∫til cuando tienes grandes vol√∫menes de logs, datos hist√≥ricos o archivos que necesitas analizar espor√°dicamente.

---

### üßæ Resumen comparativo

| Caracter√≠stica                | S3 Select                                    | Glacier Select                                |
| ----------------------------- | -------------------------------------------- | --------------------------------------------- |
| Coste                         | Bajo                                         | M√°s bajo que restauraci√≥n completa            |
| Latencia                      | Milisegundos a segundos                      | Minutos a horas (seg√∫n clase de recuperaci√≥n) |
| Casos ideales                 | An√°lisis en tiempo real de datos almacenados | Consultas puntuales sobre archivos hist√≥ricos |
| Formatos soportados           | CSV, JSON, Parquet                           | CSV, JSON                                     |
| Reduce transferencia de datos | ‚úÖ                                           | ‚úÖ                                            |
| Reduce uso de CPU en cliente  | ‚úÖ                                           | ‚úÖ                                            |

---

### üß™ Ejemplo de uso en CLI (S3 Select)

```bash
aws s3api select-object-content \
  --bucket my-data-bucket \
  --key large-file.csv \
  --expression "SELECT s._1, s._2 FROM S3Object s WHERE s._3 > 100" \
  --expression-type SQL \
  --input-serialization '{"CSV": {"FileHeaderInfo": "USE"}}' \
  --output-serialization '{"CSV": {}}' \
  output.json
```

---

## üìå Casos de uso comunes

- Analizar logs sin descargarlos completamente.
- Extraer solo las columnas necesarias para un dashboard.
- Validar datos de objetos comprimidos de forma eficiente.
- Consultas puntuales a archivos hist√≥ricos en Glacier.

## ‚öôÔ∏è S3 Batch Operations (Operaciones por lotes)

### üéØ ¬øQu√© son?

Permiten ejecutar **acciones en masa sobre millones o miles de millones de objetos S3**, con una sola solicitud gestionada por AWS.

---

### ‚úÖ ¬øQu√© operaciones se pueden hacer?

| Tipo de operaci√≥n              | ¬øQu√© hace?                                                 |
| ------------------------------ | ---------------------------------------------------------- |
| ‚úÖ **Modificar metadatos**     | Actualizar los metadatos como tipo MIME, fechas, etc.      |
| ‚úÖ **Copiar objetos**          | Entre buckets, cuentas o incluso regiones                  |
| ‚úÖ **Cifrar objetos**          | Aplicar cifrado a objetos no cifrados con SSE-S3 o SSE-KMS |
| ‚úÖ **Actualizar ACLs**         | Cambiar permisos de acceso                                 |
| ‚úÖ **Modificar etiquetas**     | A√±adir, cambiar o eliminar tags                            |
| ‚úÖ **Restaurar desde Glacier** | Restaurar objetos archivados                               |
| ‚úÖ **Invocar Lambda**          | Ejecutar c√≥digo personalizado sobre cada objeto            |
| ‚úÖ **Eliminar objetos**        | Masivamente, incluso versiones                             |

---

## üì¶ ¬øC√≥mo se estructura un trabajo de batch?

Un **trabajo (job)** consiste en:

1. ‚úÖ Una **lista de objetos** sobre los que aplicar la operaci√≥n
2. ‚úÖ La **acci√≥n** a ejecutar sobre cada objeto
3. ‚úÖ **Par√°metros adicionales** (como destino de copia, clave KMS, etc.)
4. ‚è±Ô∏è Configuraci√≥n de **notificaciones, seguimiento y reintentos**
5. üìù Opci√≥n de generar un **informe final CSV** (por √©xito/fallo)

---

### üßæ ¬øC√≥mo obtener la lista de objetos?

1. **S3 Inventory**

   - Genera archivos con el inventario de objetos de un bucket.
   - Incluye claves, tama√±o, fecha, cifrado, tags, etc.
   - √ötil como entrada para Batch Operations.

2. **S3 Select + S3 Inventory**

   - Usa **S3 Select** para **filtrar objetos relevantes** antes de pasar al lote.

---

### üîÑ Automatizaci√≥n con Lambda

- Puedes usar **AWS Lambda** para ejecutar l√≥gica personalizada en cada objeto.

  - Validaciones
  - Redimensionar im√°genes
  - Limpieza de datos
  - Generar thumbnails

> El resultado de cada invocaci√≥n se monitorea autom√°ticamente.

---

## üß™ Ejemplo: Cifrar todos los objetos no cifrados en un bucket

1. Crear un inventario con los objetos del bucket.
2. Usar S3 Select para filtrar solo los no cifrados.
3. Crear un job de Batch Operations para aplicar **SSE-KMS** a cada objeto.
4. Activar notificaciones en SNS y generaci√≥n de informe.
5. S3 gestiona el proceso, reintentos, paralelismo, y errores.

---

## üîî Ventajas

| Ventaja                   | Descripci√≥n                                 |
| ------------------------- | ------------------------------------------- |
| ‚öôÔ∏è Automatizaci√≥n         | No requiere escribir c√≥digo complejo        |
| üîÅ Reintentos autom√°ticos | AWS maneja los errores por ti               |
| üìä Seguimiento            | Puedes consultar progreso, historial y logs |
| ‚úâÔ∏è Notificaciones         | Compatible con SNS y CloudWatch Events      |
| üìÑ Informes               | Detalle de √©xito/fallo por objeto           |
| üõ°Ô∏è IAM integrado          | Control total sobre permisos y l√≠mites      |

---

## üí° Casos de uso t√≠picos

- Cifrado masivo de objetos antiguos sin cifrado.
- Aplicar nuevas ACLs a un bucket con millones de objetos.
- Copiar grandes vol√∫menes a otro bucket o regi√≥n.
- Restaurar objetos desde Glacier en lote.
- Invocar una funci√≥n Lambda para procesar contenido masivamente.

---

## üìå Resumen

| Tema                | Detalle                                                       |
| ------------------- | ------------------------------------------------------------- |
| ¬øQu√© es?            | Procesamiento masivo de objetos S3 en paralelo                |
| Acciones soportadas | Copiar, cifrar, restaurar, invocar Lambda, borrar, modificar  |
| Entrada             | Lista de objetos (ej: S3 Inventory filtrado con S3 Select)    |
| Gesti√≥n             | AWS gestiona paralelismo, reintentos, monitoreo               |
| Casos ideales       | Operaciones a gran escala sin escribir scripts personalizados |
