# Arquitecturas clÃ¡sicas

## ğŸ• Caso: Arquitectura de **WhatIsTheTime.com**

AplicaciÃ³n web sin estado que permite a los usuarios saber la hora actual. No requiere base de datos.

---

### ğŸ§ª **Etapa 1: Prueba de concepto (POC)**

- Se despliega en una sola **instancia EC2 t2.micro**.
- La instancia devuelve la hora del sistema.
- Se asigna una **Elastic IP** para acceso pÃºblico.

âŒ **Problemas:**

- MonolÃ­tica.
- Si cae la instancia, el servicio se interrumpe.
- Escalar verticalmente a una `m5.large` implica **tiempo de inactividad**.

---

### ğŸ“ˆ **Etapa 2: Escalamiento horizontal**

- En vez de escalar verticalmente, se despliega una **segunda instancia EC2**.
- Se elimina la **Elastic IP**: ya no tiene sentido una IP fija si hay mÃºltiples instancias.
- Se configura **Route 53** con un **registro A (api.whatisthetime.com)** con **TTL de 1 hora**.

âŒ **Problemas:**

- Si una instancia se cae, y el TTL es alto, los usuarios seguirÃ¡n consultando la IP incorrecta.

---

### âš–ï¸ **Etapa 3: Alta disponibilidad con balanceador**

- Se introduce un **ELB (Elastic Load Balancer)**:

  - Expone una Ãºnica IP pÃºblica.
  - Se encarga del **routing del trÃ¡fico a instancias sanas**.
  - Realiza **health checks** automÃ¡ticamente.

- Se reemplaza el **registro A** en Route 53 por un **registro Alias** apuntando al DNS del ELB.

âœ… **Beneficios:**

- Soporte para mÃºltiples instancias sin manejar IPs manualmente.
- Soporte para escalamiento dinÃ¡mico.
- ConmutaciÃ³n automÃ¡tica si una instancia falla.

---

### ğŸ“‰ **Etapa 4: Auto Scaling & optimizaciÃ³n de costes**

- Se configura un **ASG (Auto Scaling Group)**:

  - Capacidad mÃ­nima: 2 instancias.
  - Capacidad deseada: ajustada segÃºn trÃ¡fico.
  - Capacidad mÃ¡xima: para picos de carga.

- Instancias en **mÃºltiples AZ (Multi-AZ)** para alta disponibilidad.

> ğŸ’¡ Si una AZ falla (ej. terremoto), las instancias en otras zonas mantienen el servicio activo.

---

### ğŸ’° OptimizaciÃ³n de costos

- Las instancias son **bajo demanda** inicialmente.
- Se puede usar **Capacity Reservation** o **Savings Plans / RI** para reservar capacidad con descuentos a largo plazo.

---

## ğŸ§© Conceptos usados

| Componente                     | Detalles                                                                        |
| ------------------------------ | ------------------------------------------------------------------------------- |
| **Elastic IP**                 | Fija para una instancia Ãºnica, eliminada cuando se escala horizontalmente       |
| **Route 53**                   | Registro A (IP directa) â†’ Alias (apunta al ELB)                                 |
| **TTL**                        | Bajo TTL recomendado si se usan IPs variables (30sâ€“60s)                         |
| **ELB**                        | Balanceo, health checks, integraciÃ³n con ASG                                    |
| **ASG**                        | Escalado automÃ¡tico segÃºn demanda, mÃ­nimo 2 instancias para alta disponibilidad |
| **Instancias EC2**             | Sin estado, distribuidas en mÃºltiples zonas                                     |
| **Grupos de seguridad**        | Definen el trÃ¡fico permitido hacia EC2 y ELB                                    |
| **Multi-AZ**                   | Mejora la resiliencia ante fallas en una AZ                                     |
| **Health Checks**              | ELB detecta instancias no saludables                                            |
| **Capacity Reservation / RIs** | Reserva capacidad con descuento para mÃ­nimo 2 instancias                        |

---

## ğŸ—ï¸ Pilares del Well-Architected Framework aplicados

| Pilar                     | AplicaciÃ³n en la arquitectura                         |
| ------------------------- | ----------------------------------------------------- |
| ğŸ›¡ï¸ Seguridad              | Grupos de seguridad, sin acceso directo a EC2         |
| ğŸ” Fiabilidad             | Multi-AZ, ELB con health checks, ASG                  |
| ğŸ“ˆ Rendimiento            | Escalado automÃ¡tico segÃºn trÃ¡fico                     |
| ğŸ’° OptimizaciÃ³n de costos | Escalado dinÃ¡mico, RIs o Savings Plans                |
| ğŸ§° Excelencia operativa   | Despliegue sencillo, sin estado, cambios sin downtime |

---

## ğŸ‘— Caso: Arquitectura de **MyClothes.com**

AplicaciÃ³n web de e-commerce con estado (carrito de compras, datos del usuario) que:

- Tiene cientos de usuarios simultÃ¡neamente.
- Requiere **escalabilidad horizontal**.
- Debe mantener la aplicaciÃ³n **lo mÃ¡s sin estado posible** para ser escalable y resiliente.
- Debe mantener **persistencia del carrito y datos del usuario**.

---

## ğŸ§  DesafÃ­o: Â¿CÃ³mo mantener el estado del **carrito de compras**?

### 1ï¸âƒ£ **Sticky sessions del ELB** (no recomendado para HA)

- Las **sticky sessions** permiten que un usuario se mantenga con la **misma instancia EC2** durante su sesiÃ³n.
- Usan una cookie llamada `AWSELB`.

> âŒ Problema: si la instancia falla o hay un rebalanceo, **el estado se pierde**.

---

### 2ï¸âƒ£ **Almacenar estado en cookies del cliente**

- El **carrito se serializa como JSON** en una cookie.
- Las instancias siguen siendo **sin estado**.
- El frontend maneja la carga del estado.

> âš ï¸ Riesgos:

- Las cookies deben ser **< 4 KB**.
- Pueden ser manipuladas (riesgo de seguridad).
- Se debe implementar **validaciÃ³n (firma, HMAC)**.
- Las peticiones HTTP serÃ¡n mÃ¡s pesadas.

---

### 3ï¸âƒ£ **SoluciÃ³n ideal: almacenar sesiones en un backend compartido**

âœ… Mejor enfoque: usar un **backend compartido para sesiones** con un identificador Ãºnico (`session_id`) en la cookie.

#### Alternativas

| OpciÃ³n                         | Ventajas                                                                                | Consideraciones                                                     |
| ------------------------------ | --------------------------------------------------------------------------------------- | ------------------------------------------------------------------- |
| **Amazon ElastiCache (Redis)** | Millisegundos de latencia, soporte a expiraciÃ³n de sesiones, estructuras como hash/zset | Se debe usar **Multi-AZ** y grupos de seguridad                     |
| **Amazon DynamoDB**            | Sin servidor, escalado automÃ¡tico, TTL para expiraciÃ³n de sesiones                      | Latencia mayor, pero buena para aplicaciones distribuidas o mÃ³viles |

ğŸ’¡ PatrÃ³n clÃ¡sico:

1. Cliente envÃ­a `session_id` (cookie segura).
2. EC2 o Lambda lee sesiÃ³n desde **Redis o DynamoDB**.
3. Devuelve respuesta con estado persistido.

---

## ğŸ§¾ Almacenamiento de datos del usuario

- Se usa **Amazon RDS** (ej: MySQL/PostgreSQL) para datos como nombre, direcciÃ³n, historial de pedidos.
- Se puede aplicar **modelo maestro-esclavo**:

### ğŸ” ReplicaciÃ³n

- **Instancia principal** â†’ solo escritura.
- **RÃ©plica(s) de lectura** â†’ para balancear cargas de consultas.

ğŸ’¡ Alternativa avanzada:

- **Elasticache como capa de cachÃ© delante de RDS**:

  - Si hay **hit**: responde desde cachÃ©.
  - Si hay **miss**: consulta RDS y cachea el resultado.

---

## ğŸŒ Alta disponibilidad

- **Instancias EC2 y bases de datos distribuidas en varias AZ** (Multi-AZ).
- Si una AZ falla, los recursos siguen funcionando desde otra.
- **ElastiCache tambiÃ©n debe configurarse en modo Multi-AZ (con Redis cluster y rÃ©plica)**.

---

## ğŸ”’ Seguridad

| Recurso            | Medida                                                                    |
| ------------------ | ------------------------------------------------------------------------- |
| EC2 â†” ElastiCache  | Grupos de seguridad deben permitir solo el trÃ¡fico necesario              |
| EC2 â†” RDS          | Acceso restringido por grupo de seguridad                                 |
| Base de datos      | Usuarios con mÃ­nimos privilegios, sin acceso pÃºblico                      |
| Cookies de sesiÃ³n  | Deben estar firmadas o encriptadas si contienen datos sensibles           |
| Redis (AUTH) o SSL | Activar si aplica, especialmente con ElastiCache pÃºblico (no recomendado) |

---

## ğŸ“‹ Resumen general de decisiones

| Componente                     | FunciÃ³n                                        |
| ------------------------------ | ---------------------------------------------- |
| **Sticky session (ELB)**       | âŒ Solo Ãºtil si hay una Ãºnica instancia        |
| **Cookies de usuario**         | âœ… Posible, pero limitada y riesgosa           |
| **ElastiCache (Redis)**        | âœ… Ideal para sesiones rÃ¡pidas, TTL, multi-AZ  |
| **DynamoDB**                   | âœ… Alternativa serverless, buena escalabilidad |
| **RDS maestro + rÃ©plicas**     | âœ… AlmacÃ©n duradero para datos de usuario      |
| **Multi-AZ EC2 / Redis / RDS** | âœ… Alta disponibilidad y tolerancia a fallos   |
| **Grupos de seguridad**        | âœ… Control granular del trÃ¡fico                |

---

## ğŸ§  Pilares del AWS Well-Architected Framework

| Pilar                     | AplicaciÃ³n                                                      |
| ------------------------- | --------------------------------------------------------------- |
| ğŸ’° Cost Optimization      | Cacheo de lecturas, instancias por demanda con ASG              |
| âš™ï¸ Operational Excellence | Sin estado, sesiones desacopladas, escalado automÃ¡tico          |
| ğŸ” Reliability            | Multi-AZ en todos los componentes crÃ­ticos                      |
| ğŸ” Security               | Cookies seguras, trÃ¡fico interno controlado, usuarios limitados |
| ğŸ“ˆ Performance Efficiency | Redis para sesiones, rÃ©plicas para lecturas, TTLs               |

## ğŸ“ Caso: Arquitectura de **myWordpress.com**

Sitio web basado en WordPress que:

- Muestra contenido dinÃ¡mico (posts, usuarios, sesiones).
- Sube imÃ¡genes desde el frontend.
- Usa una base de datos MySQL.
- Requiere **alta disponibilidad**, **persistencia de datos** y **escalabilidad horizontal**.

---

## ğŸ§± Arquitectura inicial

| Componente                    | Uso                                                            |
| ----------------------------- | -------------------------------------------------------------- |
| **Amazon Route 53**           | DNS para `www.mywordpress.com`                                 |
| **ELB (ALB/NLB)**             | Balanceador para distribuir trÃ¡fico entre instancias           |
| **Auto Scaling Group (ASG)**  | Escala horizontalmente las EC2                                 |
| **Amazon EC2 (m5.large)**     | Servidor de WordPress                                          |
| **Amazon RDS MySQL Multi-AZ** | Base de datos relacional para posts, usuarios, configuraciones |
| **EBS (Elastic Block Store)** | Disco persistente para cada instancia                          |

---

### âŒ Problema con EBS

- EBS estÃ¡ **acoplado a una sola instancia EC2**.
- Si el usuario sube una imagen a `instancia-1`, y en su siguiente solicitud va a `instancia-2`, esa imagen **no estarÃ¡ disponible**.

---

## âœ… SoluciÃ³n: almacenamiento compartido

| Recurso                                  | SoluciÃ³n                                                          |
| ---------------------------------------- | ----------------------------------------------------------------- |
| ğŸ“· Subida de imÃ¡genes                    | Usar **EFS** (Elastic File System) para almacenamiento compartido |
| ğŸ’¾ Datos estructurados (posts, usuarios) | Usar **Aurora MySQL** (escalable y resiliente)                    |

---

### ğŸ—ƒï¸ Amazon EFS

| CaracterÃ­stica  | Detalle                                                        |
| --------------- | -------------------------------------------------------------- |
| Tipo            | File System compartido y elÃ¡stico                              |
| Acceso          | Todas las instancias EC2 pueden montarlo por NFS               |
| Multi-AZ        | âœ… Alta disponibilidad por diseÃ±o                              |
| Montaje         | A travÃ©s de **ENI (Elastic Network Interface)** en cada AZ     |
| Escenario ideal | Compartir recursos como imÃ¡genes, archivos de usuario, plugins |

> âš ï¸ EFS no es ideal para objetos grandes y frÃ­os â†’ ahÃ­ entra S3.

---

## ğŸ§  Â¿Por quÃ© no usar S3 directamente para WordPress?

| S3 es excelente para...                                            | Pero...                                                              |
| ------------------------------------------------------------------ | -------------------------------------------------------------------- |
| Sitios estÃ¡ticos, archivos JS/CSS, backups, multimedia distribuida | WordPress espera un **sistema de archivos** tradicional para uploads |
| Plugins como WP Offload Media permiten mover los uploads a S3      | Requiere ajustes extra, **no plug-and-play**                         |

---

## ğŸ’¾ Aurora MySQL para WordPress

| Funcionalidad       | Detalle                                              |
| ------------------- | ---------------------------------------------------- |
| Motor               | Aurora compatible con MySQL                          |
| Modo Multi-AZ       | Alta disponibilidad automÃ¡tica                       |
| RÃ©plicas de lectura | Para escalar consultas pesadas sin afectar escritura |
| Escenario ideal     | Wordpress con mucho trÃ¡fico, lecturas constantes     |

---

## ğŸ” Seguridad

| Recurso        | Medidas recomendadas                                               |
| -------------- | ------------------------------------------------------------------ |
| RDS/Aurora     | Solo accesible desde SG de EC2                                     |
| EFS            | Solo montable desde instancias en la misma VPC y con SG autorizado |
| EC2            | SG con acceso solo desde el ELB                                    |
| EFS Encryption | Activar cifrado en reposo y en trÃ¡nsito                            |

---

## ğŸ“‹ Resumen tÃ©cnico

| Componente   | FunciÃ³n                      | Tipo                         |
| ------------ | ---------------------------- | ---------------------------- |
| Route 53     | DNS de `www.mywordpress.com` | Alta disponibilidad          |
| ELB          | Balancea trÃ¡fico entre EC2   | Escalabilidad                |
| ASG          | Escala horizontal EC2        | Performance y disponibilidad |
| EC2 (m5)     | Servidor WordPress           | Stateless (con EFS)          |
| EBS          | Temporal / Sistema base      | Por instancia                |
| EFS          | ImÃ¡genes / Uploads           | Compartido, Multi-AZ         |
| Aurora MySQL | Base de datos de WordPress   | Multi-AZ, escalable          |
| ENI          | Permite conexiÃ³n a EFS       | Por zona                     |

---

## ğŸ§  Diferencia entre EBS, EFS y S3

| Recurso | Tipo     | Â¿Compartido? | Persistencia | Acceso                                    |
| ------- | -------- | ------------ | ------------ | ----------------------------------------- |
| **EBS** | Bloques  | âŒ No        | âœ… SÃ­        | Solo 1 instancia                          |
| **EFS** | Archivos | âœ… SÃ­        | âœ… SÃ­        | Varias instancias vÃ­a NFS                 |
| **S3**  | Objetos  | âœ… SÃ­        | âœ… SÃ­        | Acceso HTTP (no como sistema de archivos) |

---

## âœ… Pilares del Well-Architected Framework aplicados

| Pilar                     | AplicaciÃ³n                                             |
| ------------------------- | ------------------------------------------------------ |
| ğŸ” Fiabilidad             | Aurora Multi-AZ + RÃ©plicas, EC2 Multi-AZ, EFS Multi-AZ |
| ğŸ’° Cost Optimization      | ASG para escalar segÃºn demanda, lectura en Aurora      |
| ğŸ” Seguridad              | Grupos de seguridad estrictos, cifrado EFS/RDS         |
| ğŸ“ˆ Performance Efficiency | RÃ©plicas de lectura, EFS para mÃºltiples EC2            |
| âš™ï¸ Operational Excellence | SeparaciÃ³n de capas, despliegues sin acoplamiento      |

## ğŸ§± Arquitectura web clÃ¡sica de 3 niveles en AWS

Esta arquitectura suele componerse de:

| Capa                   | Componentes tÃ­picos                                  |
| ---------------------- | ---------------------------------------------------- |
| ğŸ”“ **Subred pÃºblica**  | ELB (ALB o NLB), NAT Gateway                         |
| ğŸ–¥ï¸ **Subred privada**  | EC2 (web/app servers), Auto Scaling Group            |
| ğŸ—ƒï¸ **Subred de datos** | RDS, ElastiCache, a veces S3 para recursos estÃ¡ticos |

---

## âš ï¸ Problemas comunes para desarrolladores

Aunque esta arquitectura es sÃ³lida y escalable, puede generar **fricciÃ³n** para equipos de desarrollo:

| Ãrea                                   | Dificultad                                                                |
| -------------------------------------- | ------------------------------------------------------------------------- |
| ğŸ”§ **GestiÃ³n de infraestructura**      | Hay que definir y mantener VPCs, subredes, grupos de seguridad, ELB, etc. |
| ğŸš€ **Despliegue del cÃ³digo**           | Hay que coordinar pipelines, instalaciÃ³n de dependencias, configuraciones |
| âš™ï¸ **ConfiguraciÃ³n de bases de datos** | Usuarios, backups, subredes privadas, endpoints, etc.                     |
| ğŸ“ˆ **Escalado horizontal/vertical**    | Requiere configurar ASG, polÃ­ticas de escalado, mÃ©tricas                  |
| ğŸ’° **Costos y optimizaciÃ³n**           | Ajustar tipos de instancia, escalado y tiempos de vida                    |

---

## ğŸŒ± Â¿QuÃ© es Elastic Beanstalk?

**Elastic Beanstalk** es un servicio **gestionado** que permite a los desarrolladores **desplegar y escalar rÃ¡pidamente aplicaciones web y servicios** sin gestionar la infraestructura subyacente.

### ğŸ’¡ Principio clave

> _"TÃº subes el cÃ³digo, Beanstalk hace el resto."_

---

## âœ… Beneficios clave de Beanstalk

| Ventaja           | ExplicaciÃ³n                                                                      |
| ----------------- | -------------------------------------------------------------------------------- |
| âš™ï¸ AutomatizaciÃ³n | Maneja aprovisionamiento, escalado, monitoreo y despliegue                       |
| ğŸ§  AbstracciÃ³n    | Oculta detalles complejos como VPC, ELB, ASG, etc.                               |
| ğŸªŸ Visibilidad    | AÃºn puedes ver y modificar los recursos creados                                  |
| ğŸ¯ IntegraciÃ³n    | Compatible con CloudFormation, CloudWatch, IAM, RDS, etc.                        |
| ğŸ’¸ Costo          | El servicio **no tiene costo adicional**, solo pagas por los recursos utilizados |

---

## ğŸ§© Componentes de Elastic Beanstalk

| Componente                   | DescripciÃ³n                                                                 |
| ---------------------------- | --------------------------------------------------------------------------- |
| **AplicaciÃ³n**               | Contenedor lÃ³gico del proyecto (puede tener mÃºltiples versiones y entornos) |
| **VersiÃ³n de la aplicaciÃ³n** | CÃ³digo + configuraciÃ³n especÃ­fica que puede ser desplegada                  |
| **Entorno**                  | ColecciÃ³n de recursos donde corre una versiÃ³n especÃ­fica de la aplicaciÃ³n   |

---

## ğŸ›ï¸ Tipos de entornos en Beanstalk

### ğŸŒ Entorno web (web server environment)

- Contiene:

  - ELB
  - ASG
  - Instancias EC2

- Maneja peticiones HTTP/HTTPS
- Ideal para sitios web, APIs, frontends

### âš™ï¸ Entorno de trabajo (worker environment)

- Contiene:

  - SQS (cola de tareas)
  - EC2 (workers)

- Las peticiones se encolan y los workers las procesan de forma asÃ­ncrona
- Ideal para procesamiento en segundo plano (envÃ­o de emails, procesamiento de imÃ¡genes, tareas pesadas)

ğŸ’¬ **Los entornos pueden comunicarse entre sÃ­**, por ejemplo:

- El **frontend web** encola tareas en SQS
- El **entorno worker** las consume y ejecuta

---

## ğŸ§  Plataformas soportadas por Beanstalk

| Lenguaje / Plataforma            | Â¿Soportado? |
| -------------------------------- | ----------- |
| Go                               | âœ…          |
| Java SE, Tomcat                  | âœ…          |
| .NET (Core y Framework)          | âœ…          |
| PHP                              | âœ…          |
| Node.js                          | âœ…          |
| Python                           | âœ…          |
| Ruby                             | âœ…          |
| Docker                           | âœ…          |
| Custom platform (Packer Builder) | âœ…          |

> Puedes traer tu propio contenedor o construir una plataforma personalizada con Packer si necesitas mÃ¡s control.

---

## ğŸ§­ Flujo tÃ­pico de uso

1. Desarrollador hace push del cÃ³digo (`zip`, `git`, `eb deploy`, etc.)
2. Elastic Beanstalk crea o actualiza el entorno con:

   - ELB
   - EC2 + ASG
   - RDS opcional

3. Se monitorea desde CloudWatch
4. Si falla el entorno, puedes hacer rollback con otra versiÃ³n

---

## ğŸ“‹ Resumen final

| Tema                 | Detalle                                                             |
| -------------------- | ------------------------------------------------------------------- |
| Arquitectura clÃ¡sica | 3 capas: pÃºblica, privada, datos                                    |
| Problema             | Mucho manejo de infraestructura                                     |
| SoluciÃ³n             | Elastic Beanstalk abstrae la complejidad                            |
| Control              | Puedes personalizar recursos si lo necesitas                        |
| Costos               | Solo por lo que usas (Beanstalk en sÃ­ es gratuito)                  |
| Ideal para           | Desarrolladores que quieren enfocarse en cÃ³digo, no infraestructura |

## ğŸ§Š Movimiento entre clases de almacenamiento en S3

Amazon S3 ofrece **varias clases de almacenamiento**, diseÃ±adas para diferentes patrones de acceso y requisitos de costo. Puedes mover objetos entre ellas **automÃ¡ticamente** mediante reglas de **ciclo de vida (Lifecycle rules)**.

---

### ğŸ“¦ Principales clases de almacenamiento

| Clase                       | DescripciÃ³n                                                     | Uso ideal                         |
| --------------------------- | --------------------------------------------------------------- | --------------------------------- |
| **S3 Standard**             | Alta disponibilidad, baja latencia                              | Archivos accedidos frecuentemente |
| **S3 Standard-IA**          | Infrequent Access: bajo costo, pero con tarifa por recuperaciÃ³n | Archivos accedidos ocasionalmente |
| **S3 One Zone-IA**          | Similar a Standard-IA, pero solo en 1 AZ                        | Backups no crÃ­ticos               |
| **S3 Glacier**              | Archivo con acceso en minutos u horas                           | Archivado de datos a largo plazo  |
| **S3 Glacier Deep Archive** | Acceso en 12-48h, mÃ¡s econÃ³mico                                 | Archivado casi histÃ³rico          |
| **S3 Intelligent-Tiering**  | Mueve objetos automÃ¡ticamente segÃºn patrones de acceso          | Datos con accesos impredecibles   |

---

## ğŸ” Transiciones de clase (Lifecycle Transitions)

Puedes configurar reglas que **transicionen objetos de una clase a otra** despuÃ©s de un nÃºmero de dÃ­as.

### ğŸ§  Ejemplo tÃ­pico:

1. **DÃ­a 0:** Objeto guardado en **S3 Standard**
2. **DÃ­a 60:** Mover a **S3 Standard-IA**
3. **DÃ­a 180:** Mover a **S3 Glacier**
4. **DÃ­a 365:** Eliminar el objeto (opcional)

---

## ğŸ”„ Reglas del ciclo de vida (Lifecycle Rules)

### ğŸ“Œ Â¿QuÃ© pueden hacer?

- **Transicionar objetos entre clases** segÃºn edad.
- **Eliminar objetos automÃ¡ticamente** (expiraciÃ³n).
- **Aplicarse a todo el bucket o a subconjuntos** por:

  - **Prefijo** (por ejemplo: `logs/`)
  - **Etiquetas (tags)** (por ejemplo: `{"archivado": "sÃ­"}`)

### ğŸ“˜ Sintaxis comÃºn en consola:

```plaintext
TransiciÃ³n:
- Si objeto tiene mÃ¡s de 60 dÃ­as â†’ IA
- Si objeto tiene mÃ¡s de 180 dÃ­as â†’ Glacier

ExpiraciÃ³n:
- Si objeto tiene mÃ¡s de 365 dÃ­as â†’ eliminar
```

---

## ğŸ§ª Casos de uso comunes

| Caso                           | Clase de destino     |
| ------------------------------ | -------------------- |
| Logs que se consultan poco     | IA o Glacier         |
| Archivos de cumplimiento legal | Glacier Deep Archive |
| CachÃ©s estÃ¡ticas               | S3 Standard          |
| Backups diarios                | IA o One Zone-IA     |

---

## ğŸ’¡ Recomendaciones

- Usa **tags** para tener reglas especÃ­ficas sin afectar todo el bucket.
- Glacier y Deep Archive no son instantÃ¡neos: ten presente los **tiempos de recuperaciÃ³n**.
- S3 Intelligent-Tiering puede ayudarte si **no sabes con certeza** cÃ³mo se accederÃ¡n los datos.

---

## ğŸ“‹ Resumen

| Elemento                 | Detalle                                                           |
| ------------------------ | ----------------------------------------------------------------- |
| Clases de almacenamiento | 6 principales, cada una con casos de uso                          |
| Movimiento entre clases  | Se hace con **acciones de transiciÃ³n** en reglas de ciclo de vida |
| EliminaciÃ³n automÃ¡tica   | Se hace con **acciones de expiraciÃ³n**                            |
| AplicaciÃ³n de reglas     | Por **prefijo**, **tag** o global                                 |
| Costo eficiente          | Reduce costos al mover archivos inactivos a clases mÃ¡s baratas    |
| Automatizable            | âœ… 100% con lifecycle rules y sin necesidad de scripts externos   |

## ğŸ“Š Amazon S3 Storage Class Analysis (Analytics)

### ğŸ¯ Â¿Para quÃ© sirve?

**S3 Analytics** te ayuda a analizar los patrones de acceso a los objetos almacenados en un bucket para decidir **cuÃ¡ndo moverlos automÃ¡ticamente a una clase de almacenamiento mÃ¡s econÃ³mica**, como **S3 Standard-IA**.

> Es Ãºtil especialmente cuando **no estÃ¡s seguro de la frecuencia de acceso a tus datos**.

---

## âœ… Casos de uso ideal

- Buckets con objetos en **S3 Standard** que podrÃ­an beneficiarse del cambio a **S3 Standard-IA**.
- AnÃ¡lisis previo antes de configurar reglas de ciclo de vida.
- Proyectos con gran volumen de datos y comportamiento variable.

---

## ğŸ§  CÃ³mo funciona

1. **Activas Analytics** en un bucket o prefijo.
2. AWS comienza a recopilar datos de acceso.
3. DespuÃ©s de **24 a 48 horas**, empiezas a recibir reportes.
4. Se actualiza **diariamente** y muestra:

   - Bytes almacenados
   - NÃºmero de objetos
   - Frecuencia de acceso
   - Porcentaje de acceso reciente vs histÃ³rico

5. TÃº decides si mover esos objetos a IA o no.

---

## ğŸ“ Aplicabilidad

- Puedes aplicar el anÃ¡lisis a **todo el bucket**, a **un prefijo especÃ­fico** o a **objetos con ciertas etiquetas (tags)**.
- Esto te da granularidad: puedes analizar solo los objetos que te interesan.

---

## ğŸ“‰ Ejemplo de anÃ¡lisis

Supongamos que tienes un bucket con 100 GB de datos. S3 Analytics puede mostrarte:

| Prefijo      | TamaÃ±o | % Accedido Ãºltimos 30 dÃ­as | Â¿Conviene IA? |
| ------------ | ------ | -------------------------- | ------------- |
| `/logs/`     | 30 GB  | 2%                         | âœ…            |
| `/images/`   | 50 GB  | 85%                        | âŒ            |
| `/archivos/` | 20 GB  | 5%                         | âœ…            |

---

## ğŸ§© IntegraciÃ³n con reglas de ciclo de vida

Una vez identificados los datos que no se acceden frecuentemente, puedes:

- Crear reglas de **transiciÃ³n** a **IA o Glacier**
- Crear reglas de **expiraciÃ³n**
- Aplicar reglas a los prefijos analizados

> ğŸ“Œ **S3 Analytics no realiza la transiciÃ³n automÃ¡ticamente**, pero **es un primer paso crucial**.

---

## ğŸ›‘ Limitaciones

| LimitaciÃ³n        | Detalle                                                                                        |
| ----------------- | ---------------------------------------------------------------------------------------------- |
| Tiempo inicial    | Tarda **24-48h** en generar los primeros informes                                              |
| Clases soportadas | Solo compara entre **S3 Standard** y **S3 Standard-IA**                                        |
| Costo             | **Gratuito** dentro del servicio de S3, pero hay cargos normales por almacenamiento y requests |
| No analiza        | Glacier, Deep Archive, Intelligent-Tiering, etc.                                               |

---

## ğŸ“‹ Resumen

| Tema                   | Detalle                                          |
| ---------------------- | ------------------------------------------------ |
| QuÃ© es                 | Herramienta para analizar el acceso a objetos    |
| Objetivo               | Ayudar a decidir si conviene mover a Standard-IA |
| Frecuencia de anÃ¡lisis | Diario                                           |
| Tiempo inicial         | Primer informe: 24-48 horas                      |
| Aplicable por          | Bucket, prefijo, o etiqueta                      |
| Ideal para             | Crear reglas de ciclo de vida informadas         |
| AutomatizaciÃ³n         | No realiza cambios, solo analiza                 |

## ğŸ’° S3 â€œ**Requester Pays**â€ buckets

| Concepto                     | Detalle                                                                                                                                                                                                                         |
| ---------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **Â¿QuÃ© resuelve?**           | El **propietario** de un bucket paga siempre el **almacenamiento**. Con _Requester Pays_ el **coste de las peticiones y de la transferencia de datos** (GET, LIST, PUT, egress) lo asume **quien descarga o sube los objetos**. |
| **CuÃ¡ndo usarlo**            | - Compartir grandes datasets (logs, imÃ¡genes satelitales, genomicsâ€¦) sin cargar al dueÃ±o.<br>- Repositorios pÃºblicos de investigaciÃ³n donde cada equipo cubre su propio ancho de banda.                                         |
| **Requisitos**               | ğŸ” El solicitante **debe autenticarse** con una cuenta AWS (no funciona para acceso anÃ³nimo).<br>ğŸ”‘ La **polÃ­tica**/ACL debe autorizar la acciÃ³n solicitada.<br>ğŸŒ Aplica tanto a Internet como a VPC Endpoints.                |
| **QuiÃ©n paga quÃ©**           | Propietario â‡’ _GB-mes de almacenamiento_.<br>Solicitante â‡’ _Requests_, **Data Transfer OUT**, **Data Transfer IN** (si aplica).                                                                                                 |
| **Clases de almacenamiento** | Funciona con todas; los recargos (ej. Glacier retrieval) tambiÃ©n los paga el solicitante.                                                                                                                                       |

---

### ğŸ”§ CÃ³mo activarlo

```bash
aws s3api put-bucket-request-payment \
  --bucket my-dataset-bucket \
  --request-payment-configuration Payer=Requester
```

_Para comprobar:_

```bash
aws s3api get-bucket-request-payment --bucket my-dataset-bucket
```

---

### ğŸ›‚ PolÃ­tica mÃ­nima de acceso (ejemplo)

```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "ReadOnlyRequesterPays",
      "Effect": "Allow",
      "Principal": "*",
      "Action": ["s3:GetObject"],
      "Resource": "arn:aws:s3:::my-dataset-bucket/*"
    }
  ]
}
```

> Aunque la polÃ­tica permita `*`, cada requester **debe** usar `--request-payer requester` (CLI/SDK) para que la operaciÃ³n prospere y se le facture.

---

### ğŸ§ª Uso desde CLI por parte del solicitante

```bash
aws s3 cp s3://my-dataset-bucket/bigfile.csv ./ \
  --request-payer requester
```

Sin el flag, la llamada devuelve **403 Access Denied**.

---

### âš ï¸ Consideraciones

- **Costes inesperados**: el propietario sigue pagando el almacenamiento diario.
- **Logging**: habilita Server Access Logs o CloudTrail para auditorÃ­a.
- **Cross-Account**: combina _Requester Pays_ con **Bucket Policy** o **Access Points** para precisar permisos.
- **No caching de CloudFront gratuito**: si pones el bucket detrÃ¡s de CloudFront, el dueÃ±o del CloudFront paga el egress desde la edge, no el requester.

---

### ğŸ“ Resumen rÃ¡pido

1. _Requester Pays_ = el **requester** paga **requests + transferencia**.
2. Propietario **siempre** paga **almacenamiento**.
3. Requiere **autenticaciÃ³n AWS** y `--request-payer requester`.
4. Perfecto para compartir datasets voluminosos sin facturas sorpresa.

## ğŸ“£ Notificaciones de eventos de Amazon S3

### ğŸ¯ Â¿QuÃ© son?

Permiten a S3 **notificar automÃ¡ticamente** cuando ocurren ciertos eventos sobre los objetos en un bucket, como:

- Subida (`s3:ObjectCreated:*`)
- EliminaciÃ³n (`s3:ObjectRemoved:*`)
- RestauraciÃ³n desde Glacier
- Fallos de replicaciÃ³n
- Cambios en el ciclo de vida

---

## ğŸ“ Destinos compatibles

| Destino         | Â¿Para quÃ© sirve?                                                       | CaracterÃ­sticas                                                   |
| --------------- | ---------------------------------------------------------------------- | ----------------------------------------------------------------- |
| **SNS**         | Publicar notificaciones a mÃºltiples suscriptores (email, SMS, HTTP...) | EnvÃ­o masivo y fan-out                                            |
| **SQS**         | Encolar eventos para procesamiento posterior por consumidores          | Asegura el orden, desacopla procesamiento                         |
| **Lambda**      | Ejecutar lÃ³gica directamente sobre un evento                           | Serverless, reactivo, cÃ³digo en tiempo real                       |
| **EventBridge** | Motor de eventos con reglas avanzadas, mÃºltiples destinos y fiabilidad | Filtros JSON, redirecciÃ³n de eventos, almacenamiento y repeticiÃ³n |

---

## ğŸ” Flujo tÃ­pico

1. Se sube un archivo al bucket (ej. `PUT`).
2. S3 detecta el evento `ObjectCreated:Put`.
3. EnvÃ­a notificaciÃ³n al destino configurado (ej. SQS, Lambda, etc).
4. El destino reacciona (procesa, transforma, almacenaâ€¦).

---

## ğŸ”§ ConfiguraciÃ³n bÃ¡sica (SQS, SNS, Lambda)

Se puede hacer por:

- **Consola**
- **AWS CLI**
- **S3 API** (vÃ­a `NotificationConfiguration`)

```json
{
  "LambdaFunctionConfigurations": [
    {
      "LambdaFunctionArn": "arn:aws:lambda:region:account:function:processImage",
      "Events": ["s3:ObjectCreated:*"],
      "Filter": {
        "Key": {
          "FilterRules": [
            {
              "Name": "suffix",
              "Value": ".jpg"
            }
          ]
        }
      }
    }
  ]
}
```

> TambiÃ©n puedes usar prefijos (`prefix`) para limitar eventos a carpetas especÃ­ficas.

---

## ğŸ”¥ Ventajas de usar EventBridge con S3

| Ventaja                           | Detalle                                                                                                |
| --------------------------------- | ------------------------------------------------------------------------------------------------------ |
| ğŸ¯ **Filtros potentes en JSON**   | Puedes hacer filtros por prefijo, sufijo, bucket name, regiÃ³n, o campos personalizados                 |
| ğŸš¦ **Ruteo avanzado**             | Puedes dirigir eventos a mÃºltiples destinos: Lambda, Step Functions, Kinesis, SNS, SQS, otros EventBus |
| ğŸ•’ **Reintento y entrega fiable** | Reintentos automÃ¡ticos y Dead Letter Queues                                                            |
| ğŸ”„ **RepeticiÃ³n de eventos**      | Puedes volver a emitir eventos pasados almacenados en EventBridge                                      |
| ğŸ§© **IntegraciÃ³n con SaaS**       | Puedes capturar eventos de servicios SaaS como Datadog, Auth0, MongoDB Atlas                           |
| ğŸ—‚ï¸ **Archivado de eventos**       | Puedes conservar eventos histÃ³ricos por tiempo definido                                                |

---

## ğŸ§  CuÃ¡ndo usar quÃ©

| Escenario                                        | Mejor opciÃ³n |
| ------------------------------------------------ | ------------ |
| ReacciÃ³n simple al subir archivo                 | Lambda       |
| Procesamiento en cola por lotes                  | SQS          |
| PublicaciÃ³n a mÃºltiples sistemas                 | SNS          |
| Necesitas filtros complejos o mÃºltiples destinos | EventBridge  |

---

## ğŸ§ª Ejemplo de caso real

> Se sube un archivo `.csv` al bucket `data-ingest`, y se debe:

- Validar el archivo con Lambda
- Enviar notificaciÃ³n al equipo vÃ­a SNS
- Registrar el evento en una base de eventos

ğŸ“Œ SoluciÃ³n:

- S3 envÃ­a eventos a **EventBridge**
- EventBridge enruta a:

  - Lambda para validaciÃ³n
  - SNS para alerta
  - Firehose o DynamoDB vÃ­a Lambda para almacenar eventos

---

## ğŸ§¾ Resumen

| Tema                 | Detalle                                                                      |
| -------------------- | ---------------------------------------------------------------------------- |
| Â¿QuÃ© son?            | Eventos automÃ¡ticos que lanza S3 ante acciones sobre objetos                 |
| Destinos directos    | SNS, SQS, Lambda                                                             |
| Destino avanzado     | EventBridge                                                                  |
| EventBridge ventajas | Filtros JSON, mÃºltiples destinos, repeticiÃ³n, archivado, DLQ                 |
| ConfiguraciÃ³n        | Por consola, CLI o `NotificationConfiguration`                               |
| Casos comunes        | Subida de imÃ¡genes, workflows de ingesta, validaciones, eventos distribuidos |

## ğŸš€ Rendimiento en Amazon S3

Amazon S3 estÃ¡ diseÃ±ado para **escalar automÃ¡ticamente** para soportar cargas de trabajo con alta demanda de lectura y escritura, sin necesidad de que tÃº administres el escalado.

---

### ğŸ“ˆ LÃ­mites de rendimiento por **prefijo**

| OperaciÃ³n                      | LÃ­mite por segundo **por prefijo** |
| ------------------------------ | ---------------------------------- |
| **PUT / COPY / POST / DELETE** | 3,500 requests/segundo             |
| **GET / HEAD**                 | 5,500 requests/segundo             |

ğŸ“Œ **No hay lÃ­mite en la cantidad de prefijos** que puede tener un bucket, por lo tanto puedes escalar horizontalmente tu carga de trabajo creando mÃ¡s prefijos (por ejemplo: `img/2025/07/`, `img/2025/08/`â€¦).

#### ğŸ’¡ RecomendaciÃ³n

> Distribuye objetos entre **mÃºltiples prefijos** si esperas un volumen muy alto de solicitudes concurrentes.

---

### ğŸ§© Carga de varias partes (Multipart Upload)

| CaracterÃ­stica  | Detalle                                                                                                                                                  |
| --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Â¿QuÃ© hace?      | Divide un archivo grande en partes independientes que se suben en paralelo                                                                               |
| Â¿CuÃ¡ndo usarlo? | Recomendado: archivos > 100 MB<br>Obligatorio: archivos > 5 GB                                                                                           |
| Â¿Ventajas?      | - Mejora el rendimiento<br>- RecuperaciÃ³n ante errores<br>- Posibilidad de reintento de partes fallidas<br>- Compatible con aceleraciÃ³n de transferencia |
| Â¿CÃ³mo funciona? | 1. Inicia carga<br>2. Sube partes<br>3. Finaliza la carga                                                                                                |

> Se puede hacer desde AWS CLI, SDK o S3 Console (archivos grandes).

---

### ğŸŒ AceleraciÃ³n de transferencia en S3 (Transfer Acceleration)

| CaracterÃ­stica | Detalle                                                                                                                                              |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |
| Â¿QuÃ© hace?     | Usa **Amazon CloudFront** (edge locations) para acelerar la subida y descarga de archivos a S3                                                       |
| Â¿Beneficios?   | - ReducciÃ³n de latencia en cargas y descargas<br>- Ideal para cargas de archivos desde ubicaciones globales<br>- Compatible con **multipart upload** |
| Â¿CÃ³mo usarla?  | Habilita la opciÃ³n en tu bucket y usa la URL `bucketname.s3-accelerate.amazonaws.com`                                                                |

> Ejemplo: para apps mÃ³viles o clientes globales que cargan imÃ¡genes o documentos a un bucket centralizado.

---

### ğŸ“¦ RecuperaciÃ³n de rango de bytes (Range GET)

| CaracterÃ­stica   | Detalle                                                                                                                                       |
| ---------------- | --------------------------------------------------------------------------------------------------------------------------------------------- |
| Â¿QuÃ© hace?       | Permite recuperar **solo una parte de un objeto** especificando el **rango de bytes**                                                         |
| Â¿Para quÃ© sirve? | - **Descarga paralela** de un archivo grande<br>- **Reanudar descargas** incompletas<br>- **Procesamiento parcial** sin bajar todo el archivo |
| Â¿Ejemplo?        | Descargar bytes 0â€“999 de un archivo:                                                                                                          |

```http
Range: bytes=0-999
```

ğŸ“Œ Ideal para descargas por partes en clientes como video streaming, grandes backups o descargas multi-threaded.

---

## ğŸ§  Casos de uso combinados

| Requisito                              | TÃ©cnica recomendada                  |
| -------------------------------------- | ------------------------------------ |
| Subida de archivos de 10 GB            | Multipart upload                     |
| Subida rÃ¡pida desde Asia               | Transfer Acceleration                |
| Muchas descargas simultÃ¡neas           | Distribuir prefijos y usar Range GET |
| Acceso concurrente de objetos          | MÃ¡s prefijos = mÃ¡s rendimiento       |
| Reanudar descargas sin repetir todo    | Range GET                            |
| Mejorar resiliencia en uploads grandes | Multipart upload con reintentos      |

---

## ğŸ“‹ Resumen final

| Tema                   | Detalle                                         |
| ---------------------- | ----------------------------------------------- |
| LÃ­mites de rendimiento | 3.5K escritura / 5.5K lectura por prefijo       |
| Escalado               | Usa mÃºltiples prefijos para mayor rendimiento   |
| Multipart Upload       | Paraleliza subidas, mejora tolerancia a fallos  |
| Transfer Acceleration  | Usa edge locations para mejorar latencia        |
| Range GET              | Descarga parcial o paralela de archivos grandes |

## ğŸ§  Â¿QuÃ© es S3 Select?

**S3 Select** te permite ejecutar **consultas SQL directamente sobre objetos almacenados en S3**, sin necesidad de descargar el objeto completo a tu aplicaciÃ³n o servidor.

---

### ğŸ¯ Â¿QuÃ© resuelve?

âœ… **Filtrado de datos del lado del servidor**, antes de enviarlos por red.
âœ… **ReducciÃ³n del volumen de datos transferidos**, y del uso de **CPU en el cliente**.
âœ… Ideal para leer **solo columnas o filas especÃ­ficas** de archivos grandes como CSV, JSON o Apache Parquet.

---

### ğŸ“Š Â¿CÃ³mo funciona?

1. El objeto (CSV, JSON, Parquet) estÃ¡ almacenado en S3.
2. Ejecutas una consulta SQL como:

   ```sql
   SELECT s.name, s.age FROM S3Object s WHERE s.age > 25
   ```

3. S3 procesa el archivo **dentro del servicio**.
4. Devuelve **solo las filas y columnas que cumplen la condiciÃ³n**.

> ğŸ”¸ Esto permite ahorro de ancho de banda, menos espera y menor uso de recursos cliente.

---

### ğŸ“ Formatos soportados por S3 Select

| Formato        | Soportado |
| -------------- | --------- |
| CSV            | âœ…        |
| JSON           | âœ…        |
| Apache Parquet | âœ…        |

ğŸ“Œ Comprimidos en GZIP o BZIP2: sÃ­, siempre y cuando no estÃ©n divididos en mÃºltiples bloques internos.

---

## ğŸ§Š Glacier Select

Funciona de forma muy similar a S3 Select, pero sobre **archivos archivados en S3 Glacier** o **Glacier Deep Archive**.

- Permite ejecutar consultas SQL para recuperar **solo una parte del archivo archivado**.
- Reduce el **costo y tiempo de recuperaciÃ³n**, ya que no necesitas restaurar todo el archivo.

ğŸ” Los pasos son similares: lanzas una consulta SQL, y Glacier devuelve solo el subconjunto filtrado.

> ğŸ’¡ Es especialmente Ãºtil cuando tienes grandes volÃºmenes de logs, datos histÃ³ricos o archivos que necesitas analizar esporÃ¡dicamente.

---

### ğŸ§¾ Resumen comparativo

| CaracterÃ­stica                | S3 Select                                    | Glacier Select                                |
| ----------------------------- | -------------------------------------------- | --------------------------------------------- |
| Coste                         | Bajo                                         | MÃ¡s bajo que restauraciÃ³n completa            |
| Latencia                      | Milisegundos a segundos                      | Minutos a horas (segÃºn clase de recuperaciÃ³n) |
| Casos ideales                 | AnÃ¡lisis en tiempo real de datos almacenados | Consultas puntuales sobre archivos histÃ³ricos |
| Formatos soportados           | CSV, JSON, Parquet                           | CSV, JSON                                     |
| Reduce transferencia de datos | âœ…                                           | âœ…                                            |
| Reduce uso de CPU en cliente  | âœ…                                           | âœ…                                            |

---

### ğŸ§ª Ejemplo de uso en CLI (S3 Select)

```bash
aws s3api select-object-content \
  --bucket my-data-bucket \
  --key large-file.csv \
  --expression "SELECT s._1, s._2 FROM S3Object s WHERE s._3 > 100" \
  --expression-type SQL \
  --input-serialization '{"CSV": {"FileHeaderInfo": "USE"}}' \
  --output-serialization '{"CSV": {}}' \
  output.json
```

---

## ğŸ“Œ Casos de uso comunes

- Analizar logs sin descargarlos completamente.
- Extraer solo las columnas necesarias para un dashboard.
- Validar datos de objetos comprimidos de forma eficiente.
- Consultas puntuales a archivos histÃ³ricos en Glacier.

## âš™ï¸ S3 Batch Operations (Operaciones por lotes)

### ğŸ¯ Â¿QuÃ© son?

Permiten ejecutar **acciones en masa sobre millones o miles de millones de objetos S3**, con una sola solicitud gestionada por AWS.

---

### âœ… Â¿QuÃ© operaciones se pueden hacer?

| Tipo de operaciÃ³n              | Â¿QuÃ© hace?                                                 |
| ------------------------------ | ---------------------------------------------------------- |
| âœ… **Modificar metadatos**     | Actualizar los metadatos como tipo MIME, fechas, etc.      |
| âœ… **Copiar objetos**          | Entre buckets, cuentas o incluso regiones                  |
| âœ… **Cifrar objetos**          | Aplicar cifrado a objetos no cifrados con SSE-S3 o SSE-KMS |
| âœ… **Actualizar ACLs**         | Cambiar permisos de acceso                                 |
| âœ… **Modificar etiquetas**     | AÃ±adir, cambiar o eliminar tags                            |
| âœ… **Restaurar desde Glacier** | Restaurar objetos archivados                               |
| âœ… **Invocar Lambda**          | Ejecutar cÃ³digo personalizado sobre cada objeto            |
| âœ… **Eliminar objetos**        | Masivamente, incluso versiones                             |

---

## ğŸ“¦ Â¿CÃ³mo se estructura un trabajo de batch?

Un **trabajo (job)** consiste en:

1. âœ… Una **lista de objetos** sobre los que aplicar la operaciÃ³n
2. âœ… La **acciÃ³n** a ejecutar sobre cada objeto
3. âœ… **ParÃ¡metros adicionales** (como destino de copia, clave KMS, etc.)
4. â±ï¸ ConfiguraciÃ³n de **notificaciones, seguimiento y reintentos**
5. ğŸ“ OpciÃ³n de generar un **informe final CSV** (por Ã©xito/fallo)

---

### ğŸ§¾ Â¿CÃ³mo obtener la lista de objetos?

1. **S3 Inventory**

   - Genera archivos con el inventario de objetos de un bucket.
   - Incluye claves, tamaÃ±o, fecha, cifrado, tags, etc.
   - Ãštil como entrada para Batch Operations.

2. **S3 Select + S3 Inventory**

   - Usa **S3 Select** para **filtrar objetos relevantes** antes de pasar al lote.

---

### ğŸ”„ AutomatizaciÃ³n con Lambda

- Puedes usar **AWS Lambda** para ejecutar lÃ³gica personalizada en cada objeto.

  - Validaciones
  - Redimensionar imÃ¡genes
  - Limpieza de datos
  - Generar thumbnails

> El resultado de cada invocaciÃ³n se monitorea automÃ¡ticamente.

---

## ğŸ§ª Ejemplo: Cifrar todos los objetos no cifrados en un bucket

1. Crear un inventario con los objetos del bucket.
2. Usar S3 Select para filtrar solo los no cifrados.
3. Crear un job de Batch Operations para aplicar **SSE-KMS** a cada objeto.
4. Activar notificaciones en SNS y generaciÃ³n de informe.
5. S3 gestiona el proceso, reintentos, paralelismo, y errores.

---

## ğŸ”” Ventajas

| Ventaja                   | DescripciÃ³n                                 |
| ------------------------- | ------------------------------------------- |
| âš™ï¸ AutomatizaciÃ³n         | No requiere escribir cÃ³digo complejo        |
| ğŸ” Reintentos automÃ¡ticos | AWS maneja los errores por ti               |
| ğŸ“Š Seguimiento            | Puedes consultar progreso, historial y logs |
| âœ‰ï¸ Notificaciones         | Compatible con SNS y CloudWatch Events      |
| ğŸ“„ Informes               | Detalle de Ã©xito/fallo por objeto           |
| ğŸ›¡ï¸ IAM integrado          | Control total sobre permisos y lÃ­mites      |

---

## ğŸ’¡ Casos de uso tÃ­picos

- Cifrado masivo de objetos antiguos sin cifrado.
- Aplicar nuevas ACLs a un bucket con millones de objetos.
- Copiar grandes volÃºmenes a otro bucket o regiÃ³n.
- Restaurar objetos desde Glacier en lote.
- Invocar una funciÃ³n Lambda para procesar contenido masivamente.

---

## ğŸ“Œ Resumen

| Tema                | Detalle                                                       |
| ------------------- | ------------------------------------------------------------- |
| Â¿QuÃ© es?            | Procesamiento masivo de objetos S3 en paralelo                |
| Acciones soportadas | Copiar, cifrar, restaurar, invocar Lambda, borrar, modificar  |
| Entrada             | Lista de objetos (ej: S3 Inventory filtrado con S3 Select)    |
| GestiÃ³n             | AWS gestiona paralelismo, reintentos, monitoreo               |
| Casos ideales       | Operaciones a gran escala sin escribir scripts personalizados |
