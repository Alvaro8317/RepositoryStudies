# Datos y anal√≠ticas en AWS

## Amazon Athena: servicio serverless para an√°lisis interactivo de datos en S3 mediante SQL

**Amazon Athena** es un servicio **serverless** que permite **consultar datos directamente en S3 usando SQL est√°ndar (ANSI)**, sin necesidad de mover los datos ni configurar servidores. Es ideal para an√°lisis ad hoc, inteligencia empresarial, dashboards, e integraci√≥n con servicios como **Amazon QuickSight, Metabase o Redash**.

---

### Caracter√≠sticas principales

| Caracter√≠stica             | Descripci√≥n                                                                   |
| -------------------------- | ----------------------------------------------------------------------------- |
| **Serverless**             | No requiere infraestructura, solo se paga por los datos analizados            |
| **Consulta directa en S3** | Analiza archivos en formatos abiertos                                         |
| **SQL est√°ndar (ANSI)**    | Lenguaje familiar, sin necesidad de aprender APIs espec√≠ficas                 |
| **Precio**                 | **\$5 USD por TB escaneado**, con recomendaciones para reducir costos         |
| **Integraci√≥n**            | Compatible con **QuickSight**, **Glue**, **Lake Formation**, **Lambda**, etc. |

---

### Formatos de archivos soportados

| Formato       | Descripci√≥n                                                |
| ------------- | ---------------------------------------------------------- |
| **CSV, JSON** | Comunes, pero menos eficientes en tama√±o y velocidad       |
| **Parquet**   | Columnar, comprimido, ideal para ahorrar escaneo           |
| **ORC**       | Columnar, eficiente en almacenamiento y procesamiento      |
| **Avro**      | Binario, √∫til para registros estructurados y serializaci√≥n |

> üí° **Recomendaci√≥n:** usa formatos columnar **Parquet u ORC** para mejorar el rendimiento y reducir costos.

---

### Costos y optimizaci√≥n

- **\$5 por TB de datos escaneados**
- **Buenas pr√°cticas para reducir el volumen escaneado:**

  - Comprimir archivos (Gzip, Snappy)
  - Usar formatos columnar
  - **Particionar directorios en S3**: estructura como
    `s3://mi-bucket/logs/year=2024/month=07/day=18/`
  - Usar archivos grandes de **m√°s de 128 MB** para minimizar overhead

---

### Integraci√≥n con AWS Glue

- **Glue Data Catalog**: almacena metadatos de bases y tablas
- **Glue ETL jobs**: transforma datos (ej. convertir JSON ‚Üí Parquet)
- Athena consulta los datos usando los metadatos del **Glue catalog**

---

### Consultas federadas

Athena permite **consultar datos fuera de S3**, accediendo a m√∫ltiples fuentes de datos mediante conectores (que se ejecutan en Lambda):

| Fuente                         | Descripci√≥n                                                |
| ------------------------------ | ---------------------------------------------------------- |
| **DynamoDB**                   | Consulta directa sobre tablas NoSQL                        |
| **RDS / Aurora**               | Consulta SQL relacional distribuida                        |
| **CloudWatch Logs**            | Consultas sobre logs hist√≥ricos almacenados                |
| **ElasticSearch / OpenSearch** | Consultas sobre √≠ndices de b√∫squeda                        |
| **Google BigQuery / Redshift** | (Mediante conectores o JDBC)                               |
| **Sistemas personalizados**    | Puedes crear tus propios conectores para cualquier backend |

---

### Almacenamiento de resultados

- Todos los resultados de las consultas de Athena se almacenan autom√°ticamente en un bucket de S3 configurado (por defecto en `aws-athena-query-results`)
- Puedes configurar el bucket de resultados en cada ejecuci√≥n

---

### Casos de uso comunes

| Caso de uso                         | Justificaci√≥n                                                         |
| ----------------------------------- | --------------------------------------------------------------------- |
| **An√°lisis de registros (logs)**    | Consultar logs de **VPC Flow Logs**, **ELB logs**, **S3 Access Logs** |
| **Dashboard e informes BI**         | Integraci√≥n nativa con **Amazon QuickSight**, Metabase, etc.          |
| **Data Lake exploratorio**          | Consultas puntuales sobre grandes vol√∫menes de datos                  |
| **Auditor√≠a y cumplimiento**        | Explorar logs y cambios en CloudTrail desde S3                        |
| **Consulta distribuida (federada)** | Usar SQL para consultar m√∫ltiples fuentes sin mover datos             |

---

### Comparaci√≥n r√°pida: Athena vs otras opciones

| Caracter√≠stica       | **Athena**               | **Redshift Spectrum**     | **EMR + Hive/Presto**        |
| -------------------- | ------------------------ | ------------------------- | ---------------------------- |
| Infraestructura      | Serverless               | Requiere cl√∫ster Redshift | Se debe aprovisionar cl√∫ster |
| Lenguaje             | SQL                      | SQL                       | SQL                          |
| Formatos soportados  | Parquet, ORC, JSON, etc. | Similar                   | Similar                      |
| Costo                | \$5/TB                   | Depende del cl√∫ster       | Por hora                     |
| Curva de aprendizaje | Baja                     | Media                     | Alta                         |
| Velocidad            | Alta si bien optimizado  | Alta                      | Alta si bien configurado     |

---

### Resumen t√©cnico

| Elemento                     | Valor                                           |
| ---------------------------- | ----------------------------------------------- |
| Tipo de servicio             | Consulta serverless sobre datos en S3           |
| Lenguaje de consulta         | ANSI SQL (extendido)                            |
| Coste                        | \$5 por TB escaneado                            |
| Formatos recomendados        | Parquet, ORC                                    |
| Compresi√≥n soportada         | S√≠ (gzip, snappy, zlib, etc.)                   |
| Glue integration             | S√≠, para cat√°logos y ETL                        |
| Consultas federadas          | S√≠, con conectores en Lambda                    |
| Almacenamiento de resultados | Autom√°ticamente en S3                           |
| Escenarios ideales           | Logs, an√°lisis ad hoc, dashboards BI, data lake |

---

**Amazon Athena** es la soluci√≥n ideal cuando se necesita ejecutar **consultas SQL directamente sobre datos almacenados en S3**, sin levantar infraestructura ni cargar los datos a un motor de base de datos. Su flexibilidad, escalabilidad y facilidad de integraci√≥n lo hacen una herramienta poderosa para an√°lisis en data lakes.

## Amazon Redshift: almac√©n de datos OLAP a escala de petabytes, basado en PostgreSQL

**Amazon Redshift** es un **almac√©n de datos OLAP (procesamiento anal√≠tico en l√≠nea)** totalmente gestionado por AWS, optimizado para realizar consultas anal√≠ticas complejas sobre grandes vol√∫menes de datos. A diferencia de PostgreSQL tradicional (OLTP), Redshift est√° dise√±ado para cargas de trabajo de an√°lisis intensivo, **10 veces m√°s r√°pido que otras soluciones de data warehouse**, y escala a **petabytes** con consultas paralelizadas en m√∫ltiples nodos.

---

### Arquitectura de Redshift

| Componente            | Funci√≥n                                                               |
| --------------------- | --------------------------------------------------------------------- |
| **Nodo l√≠der**        | Recibe las consultas SQL, planifica, coordina y agrega los resultados |
| **Nodos de c√≥mputo**  | Ejecutan la consulta en paralelo y devuelven los resultados al l√≠der  |
| **Cl√∫ster**           | Conjunto de nodos Redshift que funciona como una unidad               |
| **Redshift Spectrum** | Permite consultar directamente datos en S3 sin cargarlos al cl√∫ster   |

---

### Caracter√≠sticas principales de redshift

| Caracter√≠stica                            | Descripci√≥n                                                                          |
| ----------------------------------------- | ------------------------------------------------------------------------------------ |
| **Basado en PostgreSQL**                  | Usa una versi√≥n modificada, pero **no es OLTP**, sino OLAP                           |
| **Almacenamiento en columnas**            | Mejora el rendimiento de escaneo y reduce el tama√±o de los datos                     |
| **Motor de procesamiento paralelo (MPP)** | Divide las consultas en subprocesos ejecutados en paralelo                           |
| **Escala a petabytes**                    | Capacidad de escalar horizontalmente grandes vol√∫menes de datos                      |
| **Consultas SQL est√°ndar**                | Compatibilidad con SQL para agregaciones, joins, an√°lisis complejos                  |
| **Integraci√≥n con BI**                    | Compatible con **QuickSight, Tableau, Looker, Power BI**, etc.                       |
| **Pago por uso**                          | Basado en instancias aprovisionadas; opci√≥n de **instancias reservadas** para ahorro |

---

### Comparaci√≥n OLTP vs OLAP

| Caracter√≠stica | **OLTP (ej. RDS PostgreSQL)**         | **OLAP (Redshift)**                        |
| -------------- | ------------------------------------- | ------------------------------------------ |
| Uso principal  | Transacciones r√°pidas (insert/update) | An√°lisis de grandes vol√∫menes de datos     |
| Ejemplo        | Aplicaciones web, ecommerce           | Business Intelligence, informes ejecutivos |
| Consultas      | Cortas, frecuentes                    | Largas, con joins y agregaciones           |
| Almacenamiento | Por filas                             | Por columnas                               |
| Rendimiento    | Bajo en cargas anal√≠ticas complejas   | Alto con consultas masivas                 |

---

### Snapshots y recuperaci√≥n ante desastres

| Tipo de snapshot          | Descripci√≥n                                                              |
| ------------------------- | ------------------------------------------------------------------------ |
| **Autom√°ticas**           | Cada 8 horas, cada 5 GB o seg√∫n cronograma; retenci√≥n de **1 a 35 d√≠as** |
| **Manuales**              | Persisten hasta ser eliminadas                                           |
| **Almacenamiento**        | En **Amazon S3**, incrementales (solo guardan cambios)                   |
| **Restauraci√≥n**          | Se pueden restaurar a un nuevo cl√∫ster                                   |
| **Copias entre regiones** | Se pueden copiar autom√°ticamente snapshots a **otra regi√≥n** para DR     |

---

### Carga de datos en Redshift

| M√©todo de carga           | Descripci√≥n                                                    |
| ------------------------- | -------------------------------------------------------------- |
| **COPY desde S3**         | Alta eficiencia, recomendado para cargas masivas               |
| **Kinesis Data Firehose** | Ingesta automatizada en tiempo casi real                       |
| **JDBC/ODBC**             | Para cargas desde aplicaciones o herramientas de terceros      |
| **Redshift Data API**     | Para invocar operaciones SQL sin mantener conexi√≥n persistente |

> üî∏ **Insertar datos en masa es m√°s eficiente** que m√∫ltiples inserts peque√±os. Siempre que sea posible, agrupa en lotes.

---

### Redshift Spectrum: consulta sobre datos en S3

| Caracter√≠stica              | Detalles                                                                      |
| --------------------------- | ----------------------------------------------------------------------------- |
| **No carga previa**         | Permite ejecutar consultas directamente sobre datos en S3                     |
| **Requiere cl√∫ster activo** | Necesita que exista un cl√∫ster Redshift activo para ejecutar la consulta      |
| **Usa Glue Catalog**        | Define los metadatos de las tablas externas en Glue o en el cat√°logo de datos |
| **Soporta formatos**        | Parquet, ORC, Avro, CSV, JSON                                                 |
| **Escala autom√°ticamente**  | Utiliza miles de nodos en segundo plano para la ejecuci√≥n                     |

---

### Casos de uso ideales

| Caso de uso                        | Justificaci√≥n                                                           |
| ---------------------------------- | ----------------------------------------------------------------------- |
| **Inteligencia empresarial (BI)**  | Agregaciones, visualizaciones, an√°lisis masivo con SQL                  |
| **Dashboards ejecutivos**          | Uniones de m√∫ltiples fuentes para visualizaci√≥n                         |
| **Consultas anal√≠ticas complejas** | Join de millones de registros, filtros, ventanas temporales             |
| **Informes diarios/semanales**     | Optimizaci√≥n por almacenamiento columnar                                |
| **Integraci√≥n con Data Lakes**     | Con **Spectrum**, puedes consultar archivos en S3 como si fueran tablas |

---

### Redshift vs Athena

| Caracter√≠stica          | **Redshift**                                       | **Athena**                   |
| ----------------------- | -------------------------------------------------- | ---------------------------- |
| Tipo de servicio        | OLAP Data Warehouse                                | Consulta serverless sobre S3 |
| Rendimiento             | Mejor en consultas complejas con joins y agregados | Bueno para an√°lisis ad hoc   |
| Persistencia de datos   | Almacenamiento interno                             | Usa S3 directamente          |
| Costo                   | Por hora por nodo (o reservadas)                   | \$5/TB de datos escaneados   |
| Particionamiento        | Manual, por dise√±o de tablas                       | Mediante carpetas en S3      |
| Requiere cl√∫ster activo | S√≠                                                 | No                           |

---

### Resumen t√©cnico de Redshift

| Elemento                   | Valor                                              |
| -------------------------- | -------------------------------------------------- |
| Tipo de base de datos      | OLAP (almac√©n de datos anal√≠tico)                  |
| Arquitectura               | Cl√∫ster (nodo l√≠der + nodos de c√≥mputo)            |
| Almacenamiento             | Columnar                                           |
| Motor de consultas         | MPP (Massively Parallel Processing)                |
| Redshift Spectrum          | Consulta datos externos directamente desde S3      |
| Rendimiento                | Alta velocidad en consultas complejas              |
| Integraci√≥n con BI         | QuickSight, Tableau, Power BI, etc.                |
| Carga de datos recomendada | COPY desde S3 o KDF                                |
| Seguridad                  | IAM, VPC, KMS, SSL                                 |
| Snapshots                  | Autom√°ticas y manuales, retenci√≥n de hasta 35 d√≠as |
| Disaster Recovery          | Snapshots replicables a otra regi√≥n                |

---

**Amazon Redshift** es la opci√≥n recomendada para **cargas anal√≠ticas pesadas**, integraci√≥n con herramientas de BI y **consultas complejas sobre grandes vol√∫menes de datos estructurados**, con opciones para interactuar tanto con datos internos como externos (en S3) gracias a **Redshift Spectrum**. Es una soluci√≥n robusta para construir **data warehouses empresariales a escala**.

## Amazon OpenSearch: motor de b√∫squeda y an√°lisis distribuido

**Amazon OpenSearch** (anteriormente Elasticsearch Service) es un servicio gestionado que permite realizar b√∫squedas avanzadas, coincidencias parciales y an√°lisis sobre grandes vol√∫menes de datos en tiempo real. A diferencia de bases como DynamoDB, OpenSearch permite b√∫squedas no estructuradas en **cualquier campo**.

---

### Casos de uso frecuentes

- An√°lisis de logs y monitoreo
- B√∫squeda textual avanzada (por ejemplo, en aplicaciones web)
- Visualizaci√≥n de m√©tricas y dashboards en tiempo real
- Combinaci√≥n con bases de datos transaccionales para b√∫squedas secundarias

---

### Comparaci√≥n conceptual DynamoDB vs OpenSearch

| Caracter√≠stica       | **DynamoDB**                          | **OpenSearch**                                       |
| -------------------- | ------------------------------------- | ---------------------------------------------------- |
| Tipo de base         | NoSQL (claves-valor/documentos)       | Motor de b√∫squeda distribuido                        |
| Consulta por campo   | Solo por **clave primaria o √≠ndices** | Por cualquier campo, soporta coincidencias parciales |
| Lenguaje de consulta | Propietario, basado en expresiones    | DSL propio (no SQL est√°ndar)                         |
| Uso t√≠pico           | Lectura r√°pida por clave              | B√∫squeda textual, an√°lisis y agregaciones            |
| Escalado             | Serverless, bajo demanda              | Cl√∫ster de instancias                                |
| Complementariedad    | Se usa como almacenamiento principal  | Se complementa con otra BD (como DynamoDB)           |

---

### Ingesta de datos en OpenSearch

| Fuente de datos          | Mecanismo de ingesta                        |
| ------------------------ | ------------------------------------------- |
| **DynamoDB Streams**     | Stream ‚Üí Lambda ‚Üí OpenSearch                |
| **Kinesis Data Streams** | KDS ‚Üí Lambda (transformaci√≥n) ‚Üí OpenSearch  |
| **Kinesis Firehose**     | KDF ‚Üí OpenSearch (sin necesidad de Lambda)  |
| **CloudWatch Logs**      | Filtro de suscripci√≥n ‚Üí Lambda ‚Üí OpenSearch |
| **AWS IoT**              | IoT ‚Üí Kinesis / Lambda ‚Üí OpenSearch         |

---

### Seguridad

- **Autenticaci√≥n y acceso**: integraci√≥n con **IAM** y **Amazon Cognito**
- **Cifrado en tr√°nsito**: TLS
- **Cifrado en reposo**: usando **AWS KMS**
- **Control de acceso**: pol√≠ticas finas por √≠ndice y por usuario
- **OpenSearch Dashboards**: interfaz visual incluida para explorar los datos

---

### Ejemplos de patrones de arquitectura

#### üîπ Patr√≥n 1: DynamoDB + OpenSearch para b√∫squedas

```plaintext
Usuario ‚Üí API Gateway ‚Üí Lambda ‚Üí DynamoDB
                               ‚Ü≥ DynamoDB Streams ‚Üí Lambda ‚Üí OpenSearch
```

- Las operaciones CRUD se hacen sobre DynamoDB
- Los cambios son replicados a OpenSearch para permitir b√∫squedas avanzadas

---

#### üîπ Patr√≥n 2: CloudWatch Logs ‚Üí OpenSearch

```plaintext
CloudWatch Logs ‚Üí Filtro de suscripci√≥n ‚Üí Lambda ‚Üí OpenSearch
```

- Los logs de la aplicaci√≥n son procesados por Lambda y enviados a OpenSearch

---

#### üîπ Patr√≥n 3: Ingesta v√≠a Kinesis + transformaci√≥n

```plaintext
Kinesis Data Streams ‚Üí Lambda (transforma) ‚Üí OpenSearch
```

o

```plaintext
Kinesis Data Firehose ‚Üí Lambda (opcional) ‚Üí OpenSearch
```

- Para an√°lisis en tiempo casi real, con escalado autom√°tico

---

### Ventajas y consideraciones

| Ventaja                                 | Consideraci√≥n                                    |
| --------------------------------------- | ------------------------------------------------ |
| B√∫squedas r√°pidas y por cualquier campo | Requiere mantenimiento de cl√∫ster                |
| Dashboards integrados                   | No es serverless (se pagan nodos por hora)       |
| Complementa bases como DynamoDB         | No reemplaza un motor de almacenamiento primario |
| Integraci√≥n con servicios de ingesta    | No soporta SQL est√°ndar                          |

---

### Resumen t√©cnico de OpenSearch

| Elemento             | Descripci√≥n                                                     |
| -------------------- | --------------------------------------------------------------- |
| Servicio gestionado  | S√≠                                                              |
| Compatibilidad       | OpenSearch API y Dashboards                                     |
| Lenguaje de consulta | DSL de OpenSearch (no SQL)                                      |
| Escalado             | Manual o autom√°tico en cl√∫steres gestionados                    |
| Seguridad            | IAM, Cognito, TLS, KMS, control por √≠ndice                      |
| Integraciones        | Lambda, KDF, KDS, IoT, CloudWatch, DynamoDB                     |
| Visualizaci√≥n        | OpenSearch Dashboards                                           |
| Casos de uso ideales | Logs, monitoreo, an√°lisis de eventos, b√∫squeda textual flexible |

---

**Amazon OpenSearch** es ideal cuando necesitas **b√∫squedas flexibles, an√°lisis avanzado y visualizaci√≥n en tiempo real**, y se complementa com√∫nmente con bases como **DynamoDB** o servicios de streaming como **Kinesis** para habilitar arquitecturas observables, r√°pidas y escalables.

## Amazon EMR: Cl√∫steres Hadoop y procesamiento de Big Data en AWS

**Amazon EMR (Elastic MapReduce)** es un servicio gestionado que permite crear cl√∫steres de procesamiento distribuido de big data utilizando frameworks como Apache **Hadoop**, **Spark**, **Flink**, **Hive**, **HBase**, **Presto** y m√°s. Es ideal para cargas de trabajo que requieren procesamiento de grandes vol√∫menes de datos como **ETL**, **aprendizaje autom√°tico**, **indexaci√≥n web** o **an√°lisis de logs**.

---

### Caracter√≠sticas principales de EMR

- **Administraci√≥n simplificada**: EMR se encarga del **aprovisionamiento**, **configuraci√≥n**, **parcheo** y **escalado autom√°tico** del cl√∫ster.
- **Integraci√≥n con instancias Spot** para reducci√≥n de costos.
- Se puede ejecutar cl√∫steres en **EC2**, **EKS**, **Fargate** o **Outposts**.
- Compatible con almacenamiento en **S3** (como data lake), **HDFS**, **EMRFS** y **Glue Data Catalog**.

---

### Arquitectura del cl√∫ster EMR

| Rol del nodo       | Funci√≥n principal                                                                |
| ------------------ | -------------------------------------------------------------------------------- |
| **Nodo maestro**   | Coordina el cl√∫ster: gestiona la distribuci√≥n de tareas, monitorea, maneja HDFS. |
| **Nodo central**   | Ejecuta tareas y almacena datos intermedios en HDFS. Puede haber varios.         |
| **Nodo de tareas** | Ejecuta tareas de procesamiento √∫nicamente. No mantiene estado. Puede ser Spot.  |

> üîπ _Los nodos de tareas son opcionales y t√≠picamente usados como instancias Spot para tareas transitorias y econ√≥micas._

---

### Opciones de compra de instancias EC2

| Tipo de instancia | Caracter√≠sticas principales                                          |
| ----------------- | -------------------------------------------------------------------- |
| **Bajo demanda**  | Pago por hora, fiable, no se termina inesperadamente                 |
| **Reservadas**    | Compromiso de 1 o 3 a√±os, ahorro significativo, para cargas estables |
| **Spot**          | Muy econ√≥micas, pueden interrumpirse, ideales para nodos de tarea    |

---

### Tipos de cl√∫ster

| Tipo de cl√∫ster       | Descripci√≥n                                                           |
| --------------------- | --------------------------------------------------------------------- |
| **De larga duraci√≥n** | Persiste para m√∫ltiples trabajos o sesiones interactivas              |
| **Transitorio**       | Se termina autom√°ticamente tras finalizar el trabajo (ideal para ETL) |

---

### Integraciones comunes

- **S3**: Fuente/destino de datos con **EMRFS**
- **Glue Data Catalog**: Para metadatos y descubrimiento de datos
- **Athena / Redshift / QuickSight**: Como herramientas de an√°lisis sobre los resultados
- **IAM**: Control de acceso granular
- **CloudWatch**: Para logs y m√©tricas del cl√∫ster
- **Auto Scaling**: Horizontal o manual para nodos Core y Task

---

### Casos de uso

- Procesamiento de **grandes vol√∫menes de datos** (ETL, batch)
- **Aprendizaje autom√°tico** con Spark MLlib
- **Transformaci√≥n de datos** para data lakes
- **An√°lisis interactivo** con Presto
- **Indexaci√≥n y an√°lisis de logs** para motores de b√∫squeda

---

### Comparaci√≥n con otros servicios

| Servicio   | Enfoque principal                      | Diferencia clave                                         |
| ---------- | -------------------------------------- | -------------------------------------------------------- |
| **Athena** | Consultas ad-hoc SQL sobre datos en S3 | Totalmente serverless, sin gesti√≥n de cl√∫steres          |
| **Glue**   | ETL serverless                         | Menor control, ideal para cargas m√°s simples             |
| **EMR**    | Procesamiento big data personalizado   | Mayor control, elecci√≥n de frameworks, escalado flexible |

---

### Resumen t√©cnico de EMR

| Elemento                | Valor                                               |
| ----------------------- | --------------------------------------------------- |
| Frameworks soportados   | Hadoop, Spark, Hive, HBase, Flink, Presto, etc.     |
| Nodos del cl√∫ster       | Maestro, Centrales, Tareas (opcional, spot)         |
| Tipos de instancias     | Bajo demanda, reservadas, spot                      |
| Almacenamiento de datos | S3 (EMRFS), HDFS, Glue Data Catalog                 |
| Escalabilidad           | Auto Scaling con pol√≠ticas o manual                 |
| Ejecuci√≥n               | Larga duraci√≥n o transitoria                        |
| Costo                   | Pago por hora/segundo de las instancias del cl√∫ster |
| Seguridad               | IAM, KMS, VPC, SG, cifrado en tr√°nsito y en reposo  |

---

**EMR** es una soluci√≥n altamente flexible y potente para procesar grandes vol√∫menes de datos con tecnolog√≠as de c√≥digo abierto, manteniendo el control de infraestructura, frameworks y coste. Ideal para empresas que requieren personalizaci√≥n avanzada en su arquitectura de datos distribuida.

## Amazon QuickSight: An√°lisis empresarial visual e inteligente con AWS

**Amazon QuickSight** es un servicio de inteligencia empresarial (BI) totalmente gestionado, que permite crear **paneles interactivos (dashboards)** y realizar an√°lisis ad hoc sobre datos provenientes de diversas fuentes. Se destaca por su **alta escalabilidad**, **motor de machine learning**, y modelo de **precios por sesi√≥n**, lo que lo hace ideal tanto para usuarios ocasionales como frecuentes.

---

### Caracter√≠sticas clave

- **Motor SPICE (Super-fast, Parallel, In-memory Calculation Engine)**: Motor de computaci√≥n en memoria que permite an√°lisis r√°pidos sobre millones de filas sin cargar repetidamente los datos desde la fuente.
- **Machine Learning integrado**: Detecci√≥n de anomal√≠as, predicciones, generaci√≥n autom√°tica de insights con lenguaje natural (NLQ).
- **Modelo serverless y escalable**: No requiere infraestructura, y escala autom√°ticamente para miles de usuarios simult√°neos.
- **Pago por sesi√≥n**: En edici√≥n Enterprise, se paga por cada sesi√≥n iniciada (√∫til para usuarios que consultan ocasionalmente).

---

### Casos de uso t√≠picos

- An√°lisis de datos empresariales (ventas, marketing, operaciones)
- Creaci√≥n de dashboards interactivos y visuales
- Monitoreo de KPIs en tiempo real
- An√°lisis ad hoc con capacidad de filtrar, segmentar y explorar

---

### Integraci√≥n con fuentes de datos

QuickSight se conecta f√°cilmente a una variedad de servicios de AWS y fuentes externas:

| Fuente de datos en AWS | Fuente externa                   |
| ---------------------- | -------------------------------- |
| RDS                    | Salesforce                       |
| Aurora                 | Jira                             |
| Redshift               | Archivos CSV, JSON, TSV          |
| Athena                 | Bases de datos SQL y NoSQL       |
| S3                     | Servidores locales mediante ODBC |
| Timestream             |                                  |

---

### Ediciones disponibles

| Edici√≥n        | Caracter√≠sticas principales                                                                   |
| -------------- | --------------------------------------------------------------------------------------------- |
| **Standard**   | Ideal para an√°lisis individual. Sin control granular de seguridad ni usuarios corporativos.   |
| **Enterprise** | Soporte para usuarios/grupos, control de acceso a nivel de fila/columna, integraci√≥n con SSO. |

> üîê _Solo en edici√≥n Enterprise se puede aplicar CLS (Column-Level Security) y RLS (Row-Level Security)._

---

### Usuarios y grupos en QuickSight

- Se definen dentro del entorno de QuickSight, **no dependen de IAM**.
- Se pueden asignar permisos a nivel de dashboard, dataset, carpeta o columna.
- Soporta integraci√≥n con directorios corporativos (SSO) mediante SAML 2.0.

---

### Conceptos clave

| Elemento      | Descripci√≥n                                                                 |
| ------------- | --------------------------------------------------------------------------- |
| **Dataset**   | Fuente de datos preparada para an√°lisis. Puede ser directa o SPICE.         |
| **Analysis**  | Vista editable en la que se crean gr√°ficos, filtros y c√°lculos.             |
| **Dashboard** | Vista de solo lectura de un an√°lisis, compartible con otros usuarios.       |
| **SPICE**     | Motor en memoria, permite mayor velocidad y disponibilidad offline parcial. |
| **Visual**    | Gr√°fico individual dentro de un an√°lisis o dashboard.                       |

---

### Seguridad y gobernanza

- Cifrado en tr√°nsito y en reposo con **KMS**
- Control de acceso por usuario, grupo, dataset, carpeta
- **RLS/CLS** para ocultar datos seg√∫n perfil del usuario
- **Auditor√≠a y logs** mediante CloudTrail

---

### Comparaci√≥n con otras herramientas BI

| Herramienta             | Descripci√≥n breve                                       |
| ----------------------- | ------------------------------------------------------- |
| **Athena + QuickSight** | An√°lisis sobre datos en S3 usando SQL y visualizaciones |
| **Redshift + Tableau**  | An√°lisis OLAP con herramienta externa m√°s avanzada      |
| **Glue + QuickSight**   | Transformaci√≥n ETL + visualizaci√≥n final                |

---

### Ventajas principales

- Sin servidor, sin necesidad de infraestructura
- Alta escalabilidad
- Integraci√≥n nativa con todo el ecosistema de AWS
- Pago por uso en Enterprise
- Motor SPICE para consultas r√°pidas
- Ideal para dashboards empresariales compartidos con usuarios no t√©cnicos

---

QuickSight es la soluci√≥n nativa de AWS para **anal√≠tica visual, r√°pida y empresarial**, ideal para organizaciones que desean tener **informaci√≥n accionable sin gestionar infraestructura de BI**.

## AWS Lake Formation: Centralizaci√≥n de acceso y creaci√≥n eficiente de lagos de datos

**Lake Formation** es un servicio completamente gestionado que permite configurar, proteger y administrar un **lago de datos** de forma r√°pida y sencilla, centralizando tanto los datos como los controles de acceso para m√∫ltiples servicios de an√°lisis.

---

### Prop√≥sito principal de Lake Formation

- Facilita la creaci√≥n de un **Data Lake** en AWS sobre Amazon S3, combinando datos estructurados y no estructurados.
- Automatiza pasos clave del proceso como:

  - Descubrimiento de datos
  - Limpieza y transformaci√≥n
  - Ingesta
  - Deduplicaci√≥n

- Permite implementar **controles de acceso granulares** (columna, fila, tabla) desde un solo lugar, incluso para m√∫ltiples consumidores (Athena, Redshift Spectrum, EMR, QuickSight, etc.).

---

### Relaci√≥n con AWS Glue

- **Lake Formation se basa en AWS Glue**:

  - Reutiliza Glue Crawlers para descubrir esquemas
  - Comparte el **Glue Data Catalog** como fuente de metadatos
  - Puede ejecutar Glue Jobs para transformaci√≥n de datos

- Agrega una **capa adicional de control de acceso centralizado** y avanzado que Glue por s√≠ solo no ofrece.

---

### Control de acceso centralizado

Antes de Lake Formation, los permisos deb√≠an configurarse en m√∫ltiples niveles:

| Nivel      | Ejemplo de control de acceso                 |
| ---------- | -------------------------------------------- |
| IAM        | Permisos por usuario/rol a nivel de servicio |
| S3         | Pol√≠ticas de bucket y objetos                |
| Athena     | Acceso por base de datos o tabla             |
| QuickSight | Seguridad por conjunto de datos              |

Lake Formation permite **centralizar todo esto** con pol√≠ticas que controlan:

- Acceso a **tablas o columnas espec√≠ficas**
- Visibilidad condicional para diferentes usuarios
- Permisos compartidos entre cuentas (con cross-account access)
- Visibilidad basada en contexto o atributos

---

### Ejemplo: Seguridad a nivel de columna

Sup√≥n que tienes una tabla de empleados con las siguientes columnas:

- `id`, `nombre`, `departamento`, `salario`

Puedes usar Lake Formation para definir que:

- El equipo de RRHH vea todos los campos
- El equipo financiero solo vea `id`, `departamento`, `salario`
- Otros usuarios solo vean `id` y `departamento`

Esto se hace sin necesidad de duplicar tablas o datasets.

---

### Principales ventajas

| Ventaja                                                 | Descripci√≥n                                                     |
| ------------------------------------------------------- | --------------------------------------------------------------- |
| **Totalmente gestionado**                               | No requiere aprovisionamiento de servidores                     |
| **Centralizaci√≥n de permisos**                          | Acceso detallado por columna, fila, tabla, base de datos        |
| **Integraci√≥n nativa**                                  | Compatible con Glue, Athena, Redshift Spectrum, EMR, QuickSight |
| **Soporte para datos estructurados y no estructurados** | Permite analizar todo tipo de fuentes                           |
| **Escenarios multi cuenta**                             | Permite compartir recursos entre cuentas con control detallado  |

---

### Flujo general con Lake Formation

1. **Crear el Data Lake** sobre S3.
2. **Ingerir los datos** usando Glue ETL, Glue Crawlers o servicios de streaming como Kinesis.
3. **Catalogar los datos** en el Glue Data Catalog.
4. **Aplicar pol√≠ticas de acceso** a trav√©s de Lake Formation.
5. **Analizar los datos** con Athena, Redshift Spectrum, EMR o QuickSight con los permisos ya gestionados.

---

### Casos de uso frecuentes de LakeFormation

- Centralizar el acceso a datos para m√∫ltiples equipos o unidades de negocio
- Definir accesos diferenciales para datos sensibles (ej. cumplimiento GDPR)
- Compartir datasets entre cuentas AWS sin duplicar datos
- Mejorar la gobernanza de datos en entornos anal√≠ticos complejos

---

**Lake Formation** permite una gesti√≥n moderna de lagos de datos con enfoque en **gobernanza, escalabilidad y control de acceso granular**, sin la necesidad de procesos manuales complicados o desarrollos personalizados.

## Kinesis Data Analytics para SQL y Apache Flink

**Kinesis Data Analytics (KDA)** es un servicio totalmente gestionado y serverless que permite procesar y analizar flujos de datos en tiempo real mediante SQL o Apache Flink, sin necesidad de administrar servidores o cl√∫steres.

---

### Kinesis Data Analytics con SQL

- **Enfocado a desarrolladores que usan SQL**
- Permite escribir sentencias SQL est√°ndar para realizar:

  - Agregaciones en tiempo real
  - Ventanas de tiempo (tumbling, sliding, session)
  - Filtros y proyecciones de datos
  - Enriquecimiento de datos

#### Fuentes de datos

- Kinesis Data Streams (KDS)
- Kinesis Data Firehose (KDF)

#### Destinos posibles

- Kinesis Data Streams
- Kinesis Data Firehose

#### Caracter√≠sticas destacadas

| Caracter√≠stica                      | Descripci√≥n                                                              |
| ----------------------------------- | ------------------------------------------------------------------------ |
| **Enriquecimiento de datos**        | Posible mediante archivos de referencia alojados en S3                   |
| **Escalado autom√°tico**             | Adapta autom√°ticamente la capacidad a la carga                           |
| **Pago por consumo real**           | Solo se cobra por los recursos utilizados                                |
| **Transformaciones en tiempo real** | Los resultados se pueden enviar a otros servicios para consumo inmediato |

#### Ejemplo de flujo con SQL

```text
Kinesis Data Stream (fuente)
   ‚Üì
Kinesis Data Analytics con SQL
   - SELECT sensor_id, AVG(temp) OVER 1 MINUTE ...
   - JOIN con archivo CSV en S3
   ‚Üì
Kinesis Firehose (destino) ‚Üí S3, Redshift, OpenSearch
```

---

### Kinesis Data Analytics con Apache Flink

- Permite ejecutar **aplicaciones personalizadas en streaming** utilizando:

  - Java
  - Scala
  - SQL

#### Capacidades de Flink

- Procesamiento **estadoful** de eventos
- Tolerancia a fallos (checkpoints, backup)
- **Computaci√≥n paralela** y en cl√∫ster
- **Programaci√≥n avanzada** (por ejemplo, uniones, ventanas personalizadas, patrones de eventos con CEP)

#### Or√≠genes y destinos

| Tipo         | Servicios compatibles                                        |
| ------------ | ------------------------------------------------------------ |
| **Or√≠genes** | Kinesis Data Streams, Amazon MSK, Apache Kafka (no Firehose) |
| **Destinos** | Kinesis Data Streams, MSK, S3, Redshift, etc.                |

> üî¥ **Importante:** Apache Flink **no puede leer desde Kinesis Data Firehose**, ya que este no expone un stream legible en tiempo real.

#### Flujo con Flink

```text
MSK / KDS (origen)
   ‚Üì
Kinesis Data Analytics con Apache Flink (c√≥digo Java/Scala)
   ‚Üì
Kinesis Data Streams / S3 / Redshift / OpenSearch (destino)
```

#### Caracter√≠sticas adicionales

- Aplicaciones resilientes con backups autom√°ticos
- Integraci√≥n con m√©tricas y logs de CloudWatch
- Procesamiento con **baja latencia y alta capacidad de paralelismo**

---

### Comparaci√≥n r√°pida entre SQL y Apache Flink

| Caracter√≠stica          | SQL                           | Apache Flink                     |
| ----------------------- | ----------------------------- | -------------------------------- |
| Lenguaje                | SQL est√°ndar                  | Java, Scala, SQL (Flink SQL)     |
| Complejidad             | Baja                          | Alta (pero m√°s flexible)         |
| Escenarios recomendados | Filtros, agregaciones simples | Procesamiento complejo, patrones |
| Escalado autom√°tico     | S√≠                            | S√≠                               |
| Enriquecimiento con S3  | S√≠                            | S√≠                               |
| Lectura desde Firehose  | ‚úÖ                            | ‚ùå                               |
| Latencia                | Baja                          | Muy baja                         |

---

### Casos de uso comunes de KDS

- **SQL**: detecci√≥n de anomal√≠as en sensores IoT, c√°lculo de KPIs en tiempo real, agregaciones por ventana.
- **Flink**: procesamiento de logs, detecci√≥n de fraudes, correlaci√≥n de eventos, machine learning en streaming.

---

**Kinesis Data Analytics**, ya sea con **SQL o Apache Flink**, es una soluci√≥n robusta para ejecutar an√°lisis en tiempo real directamente sobre flujos de datos, con gran integraci√≥n en el ecosistema de AWS y adecuada tanto para casos simples como para arquitecturas complejas de streaming.

### Comparaci√≥n entre Amazon Kinesis Data Streams (KDS) y Amazon MSK (Managed Streaming for Apache Kafka)

| Caracter√≠stica                          | **Kinesis Data Streams (KDS)**                                 | **Amazon MSK (Kafka)**                                           |
| --------------------------------------- | -------------------------------------------------------------- | ---------------------------------------------------------------- |
| **Naturaleza**                          | Servicio propietario de AWS                                    | Plataforma de streaming basada en Apache Kafka (open source)     |
| **Administraci√≥n**                      | Totalmente gestionado                                          | Totalmente gestionado                                            |
| **Modelo de datos**                     | Flujos con **shards** (fragmentos)                             | **Temas con particiones**                                        |
| **Particiones**                         | Shards se pueden dividir o fusionar din√°micamente              | Particiones son fijas; solo se pueden **agregar**, no eliminar   |
| **Protocolo**                           | Propietario de AWS (SDK, KPL/KCL)                              | Compatible con protocolo Kafka (producers/consumers est√°ndar)    |
| **Tama√±o m√°ximo de registro**           | **1 MB por registro**                                          | **1 MB por defecto**, pero **configurable**                      |
| **Retenci√≥n de datos**                  | De **1 a 365 d√≠as**                                            | Configurable desde horas hasta d√≠as o indefinido                 |
| **Reproducci√≥n de datos (replay)**      | Soportado, gracias al almacenamiento inmutable                 | Soportado mientras los datos est√©n retenidos                     |
| **Ordenaci√≥n**                          | Garantizada dentro de un shard por clave de partici√≥n          | Garantizada dentro de una partici√≥n                              |
| **Escalado**                            | Manual (modo aprovisionado) o autom√°tico (modo on-demand)      | Basado en n√∫mero de particiones y tama√±o del cl√∫ster             |
| **Integraci√≥n con otros servicios AWS** | Alta (Lambda, Firehose, Analytics, etc.)                       | Media (requiere m√°s configuraci√≥n, uso de conectores Kafka)      |
| **Cifrado en tr√°nsito**                 | TLS                                                            | TLS o plaintext (ambos disponibles)                              |
| **Cifrado en reposo**                   | KMS                                                            | KMS o AWS-managed keys con EBS                                   |
| **VPC**                                 | Compatible con endpoints VPC                                   | Se implementa dentro de una VPC multi-AZ                         |
| **Tolerancia a fallos**                 | S√≠ (alta disponibilidad por dise√±o del servicio)               | S√≠ (multi-AZ con recuperaci√≥n autom√°tica de brokers y ZooKeeper) |
| **Costo y complejidad de operaci√≥n**    | Menor complejidad, menos flexible                              | Mayor control y flexibilidad, mayor complejidad operativa        |
| **Uso recomendado**                     | Integraci√≥n r√°pida y sencilla con AWS, an√°lisis en tiempo real | Migraci√≥n desde Kafka, integraci√≥n con herramientas Kafka        |

---

### Conclusiones

- **KDS** es ideal si necesitas una soluci√≥n _nativa de AWS_, m√°s f√°cil de usar, con integraci√≥n profunda con otros servicios y suficiente para la mayor√≠a de escenarios de streaming est√°ndar.
- **MSK** es ideal si ya usas **Apache Kafka**, necesitas _compatibilidad completa con su ecosistema_, o requieres configuraciones m√°s personalizadas (como modificar tama√±o de mensaje, retenci√≥n, replicaci√≥n, etc.).

Ambas opciones permiten transmitir, almacenar y procesar flujos de datos, pero **KDS prioriza simplicidad** y **MSK prioriza compatibilidad y flexibilidad**.

### Arquitectura Serverless para un Pipeline de Ingesta de Big Data

#### 1. **Recopilaci√≥n de datos en tiempo real (IoT Core ‚Üí Kinesis Data Streams)**

- Los dispositivos IoT env√≠an datos continuamente.
- **AWS IoT Core** act√∫a como gateway seguro y administrado.
- Los datos se enrutan directamente a **Kinesis Data Streams (KDS)** para procesarlos en tiempo real.

#### 2. **Transformaci√≥n y almacenamiento (KDS ‚Üí Firehose ‚Üí Lambda ‚Üí S3)**

- **Kinesis Data Firehose** toma los datos desde KDS.
- Aplica una funci√≥n **Lambda para transformaci√≥n en tiempo de ejecuci√≥n** (por ejemplo, limpieza o enriquecimiento de datos).
- Firehose entrega los datos transformados a un **bucket S3**.

#### 3. **Procesamiento adicional (SQS ‚Üí Lambda ‚Üí Athena ‚Üí S3 Reportes)**

- Se puede a√±adir una **cola SQS** para desacoplar el procesamiento.
- Una **Lambda** act√∫a como consumidor de SQS, y lanza **consultas en Athena** usando SQL para procesar los datos almacenados en S3.
- Athena puede generar resultados en otro bucket **S3 de reportes**.

#### 4. **Visualizaci√≥n y almacenamiento anal√≠tico (QuickSight / Redshift)**

- Los datos procesados y almacenados en S3 pueden:
  - Ser consultados directamente desde **Amazon QuickSight** para dashboards e informes interactivos.
  - O ser cargados a **Amazon Redshift** como almac√©n de datos OLAP para consultas anal√≠ticas m√°s complejas y agregaciones de grandes vol√∫menes.

---

### Diagrama resumen

```plaintext

Dispositivos IoT
‚Üì
AWS IoT Core
‚Üì
Kinesis Data Streams
‚Üì
Kinesis Data Firehose
‚Üì ‚Üí (opcional) ‚Üí SQS ‚Üí Lambda ‚Üí Athena ‚Üí S3 (reportes)
Lambda (transformaci√≥n)
‚Üì
S3 (raw / staging)
‚Üì
QuickSight / Redshift
```

---

### Caracter√≠sticas Clave del Pipeline

| Componente            | Rol                                                    |
| --------------------- | ------------------------------------------------------ |
| IoT Core              | Recepci√≥n de datos de sensores / dispositivos          |
| KDS                   | Canalizaci√≥n de datos en tiempo real                   |
| Firehose              | Transformaci√≥n b√°sica + entrega a S3                   |
| Lambda                | Transformaci√≥n personalizada / procesamiento disparado |
| SQS                   | Desacoplamiento del procesamiento                      |
| Athena                | Consultas ad hoc en S3 con SQL                         |
| S3                    | Almacenamiento centralizado, staging y resultados      |
| QuickSight / Redshift | Visualizaci√≥n de datos / an√°lisis profundo             |

---

Este enfoque es **completamente serverless**, escalable y optimizado para escenarios de big data en tiempo real con transformaci√≥n, an√°lisis y visualizaci√≥n.
